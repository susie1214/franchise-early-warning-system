# -*- coding: utf-8 -*-
"""
ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ (Pure ML ë²„ì „)
- 4ë‹¨ê³„ ê²½ë³´ ì‹œìŠ¤í…œ: ì•ˆì „(Green) -> ì£¼ì˜(Yellow) -> ê²½ê³ (Orange) -> ìœ„í—˜(Red)
- ìˆœìˆ˜ LightGBM ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ (ë£° ê¸°ë°˜ ì œê±°)
- ëª¨ë“  ë°ì´í„°ì…‹ íŠ¹ì„± í™œìš© (set1, set2, set3, rental, flow)
- ì„¸ëŒ€ë³„ ë§¤ì¶œ ë³€í™” ë¶„ì„ í¬í•¨
- ë¶„ì„ ê¸°ê°„: 2023-01 ~ 2024-12
"""

import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

import lightgbm as lgb
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import shap

# OpenAI API (ì„ íƒì‚¬í•­)
try:
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    load_dotenv()  # .env íŒŒì¼ ë¡œë“œ
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸  OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ë¶„ì„ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install openai python-dotenv")

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

class MLEarlyWarningSystem:
    """Pure ML ê¸°ë°˜ ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ"""

    def __init__(self, data_path='./data/', start_date='2023-01', end_date='2024-12'):
        """ì´ˆê¸°í™”"""
        self.data_path = data_path
        self.start_date = pd.to_datetime(start_date, format='%Y-%m')
        self.end_date = pd.to_datetime(end_date, format='%Y-%m')

        self.merchant_data = None
        self.sales_data = None
        self.customer_data = None
        self.rental_data = None
        self.flow_data = None
        self.merged_data = None
        self.model = None
        self.feature_cols = []
        self.label_encoders = {}

        # ê²½ë³´ ë ˆë²¨ ì •ì˜
        self.WARNING_LEVELS = {
            0: {'name': 'ì•ˆì „', 'color': 'green', 'emoji': 'ğŸŸ¢'},
            1: {'name': 'ì£¼ì˜', 'color': 'yellow', 'emoji': 'ğŸŸ¡'},
            2: {'name': 'ê²½ê³ ', 'color': 'orange', 'emoji': 'ğŸŸ '},
            3: {'name': 'ìœ„í—˜', 'color': 'red', 'emoji': 'ğŸ”´'}
        }

        # LLM ì„¤ì •
        self.use_llm = OPENAI_AVAILABLE and os.getenv('USE_LLM_ANALYSIS', 'false').lower() == 'true'
        self.openai_client = None
        self.openai_model = os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo')

        if self.use_llm:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key and api_key != 'your-api-key-here':
                self.openai_client = OpenAI(api_key=api_key)
                print(f"âœ… LLM ë¶„ì„ í™œì„±í™” (ëª¨ë¸: {self.openai_model})")
            else:
                self.use_llm = False
                print("âš ï¸  OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ë¶„ì„ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        else:
            print("â„¹ï¸  LLM ë¶„ì„ ë¹„í™œì„±í™” (ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ)")

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("=" * 80)
        print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘ ({self.start_date.strftime('%Y-%m')} ~ {self.end_date.strftime('%Y-%m')})")
        print("=" * 80)

        # ê°€ë§¹ì  ì •ë³´
        self.merchant_data = pd.read_csv(f'{self.data_path}big_data_set1_f_v2.csv', encoding='utf-8-sig')
        print(f"âœ“ ê°€ë§¹ì  ì •ë³´: {len(self.merchant_data):,}ê°œ")

        # ë§¤ì¶œ ë°ì´í„°
        self.sales_data = pd.read_csv(f'{self.data_path}big_data_set2_f_sorted.csv', encoding='utf-8-sig')
        self.sales_data['TA_YM'] = pd.to_datetime(self.sales_data['TA_YM'], format='%Y%m')

        # ê¸°ê°„ í•„í„°ë§
        self.sales_data = self.sales_data[
            (self.sales_data['TA_YM'] >= self.start_date) &
            (self.sales_data['TA_YM'] <= self.end_date)
        ]
        print(f"âœ“ ë§¤ì¶œ ë°ì´í„°: {len(self.sales_data):,}ê±´ ({self.start_date.strftime('%Y-%m')} ~ {self.end_date.strftime('%Y-%m')})")

        # ê³ ê° ë°ì´í„°
        self.customer_data = pd.read_csv(f'{self.data_path}big_data_set3_f_sorted.csv', encoding='utf-8-sig')
        self.customer_data['TA_YM'] = pd.to_datetime(self.customer_data['TA_YM'], format='%Y%m')

        # ê¸°ê°„ í•„í„°ë§
        self.customer_data = self.customer_data[
            (self.customer_data['TA_YM'] >= self.start_date) &
            (self.customer_data['TA_YM'] <= self.end_date)
        ]
        print(f"âœ“ ê³ ê° ë°ì´í„°: {len(self.customer_data):,}ê±´")

        # ì„ëŒ€ë£Œ ë°ì´í„°
        self.rental_data = pd.read_csv(f'{self.data_path}rental_p.csv', encoding='utf-8-sig')
        print(f"âœ“ ì„ëŒ€ë£Œ ë°ì´í„°: {len(self.rental_data):,}ê±´")

        # ìœ ë™ì¸êµ¬ ë°ì´í„°
        self.flow_data = pd.read_csv(f'{self.data_path}flow_f.csv', encoding='utf-8-sig')
        print(f"âœ“ ìœ ë™ì¸êµ¬ ë°ì´í„°: {len(self.flow_data):,}ê±´")
        print()

    def merge_all_data(self):
        """ëª¨ë“  ë°ì´í„° í†µí•©"""
        print("ğŸ”— ë°ì´í„° í†µí•© ì¤‘...")

        # ë§¤ì¶œ + ê³ ê° ë°ì´í„°
        self.merged_data = pd.merge(
            self.sales_data,
            self.customer_data,
            on=['ENCODED_MCT', 'TA_YM'],
            how='inner'
        )

        # ê°€ë§¹ì  ì •ë³´ ì¶”ê°€
        self.merged_data = pd.merge(
            self.merged_data,
            self.merchant_data[['ENCODED_MCT', 'MCT_NM', 'HPSN_MCT_ZCD_NM', 'HPSN_MCT_BZN_CD_NM',
                                'MCT_SIGUNGU_NM', 'LEGAL_DONG', 'ARE_D']],
            on='ENCODED_MCT',
            how='left'
        )

        # ì„ëŒ€ë£Œ ë°ì´í„° (ë¶„ê¸° -> ì›”ë¡œ í™•ì¥)
        self.rental_data['ê¸°ê°„(ë¶„ê¸°)'] = pd.to_datetime(self.rental_data['ê¸°ê°„(ë¶„ê¸°)'], format='%Y%m')
        rental_expanded = []
        for _, row in self.rental_data.iterrows():
            for i in range(3):
                new_row = row.copy()
                new_row['TA_YM'] = row['ê¸°ê°„(ë¶„ê¸°)'] + pd.DateOffset(months=i)
                rental_expanded.append(new_row)

        rental_df = pd.DataFrame(rental_expanded)

        # ê¸°ê°„ í•„í„°ë§
        rental_df = rental_df[
            (rental_df['TA_YM'] >= self.start_date) &
            (rental_df['TA_YM'] <= self.end_date)
        ]

        self.merged_data = pd.merge(
            self.merged_data,
            rental_df[['TA_YM', 'í–‰ì •êµ¬ì—­', 'ì „ì²´(ë‹¨ìœ„:ì›/í‰)', '1ì¸µ(ë‹¨ìœ„:ì›/í‰)', '1ì¸µ ì™¸(ë‹¨ìœ„:ì›/í‰)']],
            left_on=['TA_YM', 'LEGAL_DONG'],
            right_on=['TA_YM', 'í–‰ì •êµ¬ì—­'],
            how='left'
        )
        
        # ìœ ë™ì¸êµ¬ ë°ì´í„° (ë¶„ê¸° -> ì›”ë¡œ í™•ì¥)
        self.flow_data['ê¸°ê°„(ë¶„ê¸°)'] = pd.to_datetime(self.flow_data['ê¸°ê°„(ë¶„ê¸°)'], format='%Y%m')
        flow_expanded = []
        for _, row in self.flow_data.iterrows():
            for i in range(3):
                new_row = row.copy()
                new_row['TA_YM'] = row['ê¸°ê°„(ë¶„ê¸°)'] + pd.DateOffset(months=i)
                flow_expanded.append(new_row)

        flow_df = pd.DataFrame(flow_expanded)

        # ê¸°ê°„ í•„í„°ë§
        flow_df = flow_df[
            (flow_df['TA_YM'] >= self.start_date) &
            (flow_df['TA_YM'] <= self.end_date)
        ]

        self.merged_data = pd.merge(
            self.merged_data,
            flow_df[['TA_YM', 'í–‰ì êµ¬ì—­', 'ìœ ë™ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)', 'ì£¼ê±°ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)', 'ì§ì¥ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)']],
            left_on=['TA_YM', 'LEGAL_DONG'],
            right_on=['TA_YM', 'í–‰ì êµ¬ì—­'],
            how='left'
        )
        
        print(f"ì„ëŒ€ë£Œ \n {self.merged_data.head()}")

        print(f"âœ“ í†µí•© ë°ì´í„°: {len(self.merged_data):,}ê±´")
        print(f"  ê¸°ê°„: {self.merged_data['TA_YM'].min().strftime('%Y-%m')} ~ {self.merged_data['TA_YM'].max().strftime('%Y-%m')}")
        print(f"  ê°€ë§¹ì  ìˆ˜: {self.merged_data['ENCODED_MCT'].nunique():,}ê°œ\n")

    def extract_numeric_value(self, value_str):
        """êµ¬ê°„ ë¬¸ìì—´ì—ì„œ ì¤‘ê°„ê°’ ì¶”ì¶œ"""
        if pd.isna(value_str) or value_str == '':
            return np.nan

        value_str = str(value_str)

        if '90%ì´ˆê³¼' in value_str or 'í•˜ìœ„ 10%' in value_str:
            return 95.0

        if '_' in value_str and '%' in value_str:
            parts = value_str.split('_')
            if len(parts) > 1:
                range_part = parts[1].replace('%', '')
                if '-' in range_part:
                    low, high = map(float, range_part.split('-'))
                    return (low + high) / 2
                elif 'ì´í•˜' in range_part:
                    return float(range_part.replace('ì´í•˜', '')) / 2

        return np.nan

    def create_comprehensive_features(self):
        """ëª¨ë“  ë°ì´í„°ì…‹ì„ í™œìš©í•œ ì¢…í•© íŠ¹ì„± ìƒì„±"""
        print("ğŸ”§ ì¢…í•© íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")

        # ì •ë ¬
        self.merged_data = self.merged_data.sort_values(['ENCODED_MCT', 'TA_YM'])

        # === 1. ê¸°ë³¸ ì‹œê³„ì—´ ì •ë³´ ===
        self.merged_data['ìš´ì˜ê°œì›”ìˆ˜'] = self.merged_data.groupby('ENCODED_MCT').cumcount() + 1
        self.merged_data['ì›”'] = self.merged_data['TA_YM'].dt.month
        self.merged_data['ë¶„ê¸°'] = self.merged_data['TA_YM'].dt.quarter
        self.merged_data['ì—°ë„'] = self.merged_data['TA_YM'].dt.year

        # === 2. ë§¤ì¶œ ë°ì´í„° (set2) ìˆ«ìí˜• ë³€í™˜ ===
        sales_cols = [
            'MCT_OPE_MS_CN', 'RC_M1_SAA', 'RC_M1_TO_UE_CT', 'RC_M1_UE_CUS_CN', 'RC_M1_AV_NP_AT',
            'M12_SME_RY_SAA_PCE_RT', 'M12_SME_BZN_SAA_PCE_RT', 'DLV_SAA_RAT'
        ]

        for col in sales_cols:
            if col in self.merged_data.columns:
                self.merged_data[f'{col}_num'] = self.merged_data[col].apply(self.extract_numeric_value)

        # ìŠ¹ì¸ìœ¨
        if 'APV_CE_RAT' in self.merged_data.columns:
            self.merged_data['APV_CE_RAT'] = self.merged_data['APV_CE_RAT'].replace('', np.nan)
            self.merged_data['APV_CE_RAT_num'] = self.merged_data['APV_CE_RAT'].apply(
                lambda x: self.extract_numeric_value(x) if pd.notna(x) else np.nan
            )

        # === 3. ê³ ê° ë°ì´í„° (set3) ì²˜ë¦¬ ===

        # -999999.9 ê°’ì„ nullë¡œ ì²˜ë¦¬
        self.merged_data = self.merged_data.replace(-999999.9, np.nan)

        # 3-1. ì„±ë³„/ì—°ë ¹ë³„ ë¹„ìœ¨ (ìˆ«ìí˜• ë³€í™˜)
        demographic_cols = [
            'M12_MAL_1020_RAT', 'M12_MAL_30_RAT', 'M12_MAL_40_RAT', 'M12_MAL_50_RAT', 'M12_MAL_60_RAT',
            'M12_FME_1020_RAT', 'M12_FME_30_RAT', 'M12_FME_40_RAT', 'M12_FME_50_RAT', 'M12_FME_60_RAT'
        ]

        for col in demographic_cols:
            if col in self.merged_data.columns:
                self.merged_data[col] = pd.to_numeric(self.merged_data[col], errors='coerce')

        # 3-2. ì¬êµ¬ë§¤/ì‹ ê·œ ê³ ê° ë¹„ìœ¨
        if 'MCT_UE_CLN_REU_RAT' in self.merged_data.columns:
            self.merged_data['MCT_UE_CLN_REU_RAT'] = pd.to_numeric(
                self.merged_data['MCT_UE_CLN_REU_RAT'], errors='coerce'
            )

        if 'MCT_UE_CLN_NEW_RAT' in self.merged_data.columns:
            self.merged_data['MCT_UE_CLN_NEW_RAT'] = pd.to_numeric(
                self.merged_data['MCT_UE_CLN_NEW_RAT'], errors='coerce'
            )

        # 3-3. ê±°ì£¼/ì§ì¥/ìœ ì… ê³ ê° ë¹„ìœ¨ ì»¬ëŸ¼ ì œê±° (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        # RC_M1_SHC_RSD_UE_CLN_RAT, RC_M1_SHC_WP_UE_CLN_RAT, RC_M1_SHC_FLP_UE_CLN_RAT
        unused_location_cols = ['RC_M1_SHC_RSD_UE_CLN_RAT', 'RC_M1_SHC_WP_UE_CLN_RAT', 'RC_M1_SHC_FLP_UE_CLN_RAT']
        for col in unused_location_cols:
            if col in self.merged_data.columns:
                self.merged_data = self.merged_data.drop(columns=[col])

        print(f"  âœ“ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì œê±°: {unused_location_cols}")

        # === 4. ì„¸ëŒ€ë³„(ì—°ë ¹ëŒ€ë³„) ë§¤ì¶œ íŠ¹ì„± ìƒì„± ===
        print("  ğŸ“Š ì„¸ëŒ€ë³„ ë§¤ì¶œ ë¶„ì„ ì¤‘...")

        # 4-1. ì„¸ëŒ€ë³„ ë§¤ì¶œ ì§‘ì¤‘ë„
        male_cols = [c for c in demographic_cols if 'MAL' in c]
        female_cols = [c for c in demographic_cols if 'FME' in c]

        # ë‚¨ì„± ê³ ê° ë¹„ì¤‘
        if male_cols:
            self.merged_data['ë‚¨ì„±ê³ ê°_ë¹„ì¤‘'] = self.merged_data[male_cols].sum(axis=1)

        # ì—¬ì„± ê³ ê° ë¹„ì¤‘
        if female_cols:
            self.merged_data['ì—¬ì„±ê³ ê°_ë¹„ì¤‘'] = self.merged_data[female_cols].sum(axis=1)

        # ì—°ë ¹ëŒ€ë³„ ì§‘ì¤‘ë„
        if 'M12_MAL_1020_RAT' in self.merged_data.columns and 'M12_FME_1020_RAT' in self.merged_data.columns:
            self.merged_data['2030ì„¸ëŒ€_ë¹„ì¤‘'] = (
                self.merged_data['M12_MAL_1020_RAT'] + self.merged_data['M12_MAL_30_RAT'] +
                self.merged_data['M12_FME_1020_RAT'] + self.merged_data['M12_FME_30_RAT']
            )

            self.merged_data['4050ì„¸ëŒ€_ë¹„ì¤‘'] = (
                self.merged_data['M12_MAL_40_RAT'] + self.merged_data['M12_MAL_50_RAT'] +
                self.merged_data['M12_FME_40_RAT'] + self.merged_data['M12_FME_50_RAT']
            )

            self.merged_data['60ëŒ€ì´ìƒ_ë¹„ì¤‘'] = (
                self.merged_data['M12_MAL_60_RAT'] + self.merged_data['M12_FME_60_RAT']
            )

        # 4-2. ì„¸ëŒ€ë³„ ë³€í™”ìœ¨ (1ê°œì›”, 3ê°œì›”)
        generation_cols = ['2030ì„¸ëŒ€_ë¹„ì¤‘', '4050ì„¸ëŒ€_ë¹„ì¤‘', '60ëŒ€ì´ìƒ_ë¹„ì¤‘']

        for col in generation_cols:
            if col in self.merged_data.columns:
                # 1ê°œì›” ë³€í™”
                self.merged_data[f'{col}_ë³€í™”_1M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].diff(1)

                # 3ê°œì›” ë³€í™”
                self.merged_data[f'{col}_ë³€í™”_3M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].diff(3)

        # 4-3. ì£¼ë ¥ ì„¸ëŒ€ ì‹ë³„
        if all(col in self.merged_data.columns for col in generation_cols):
            def get_main_generation(row):
                # ëª¨ë“  ì„¸ëŒ€ ë¹„ì¤‘ì´ NaNì´ë©´ None ë°˜í™˜ (ë‚˜ì¤‘ì— ì²˜ë¦¬)
                if pd.isna(row['2030ì„¸ëŒ€_ë¹„ì¤‘']) and pd.isna(row['4050ì„¸ëŒ€_ë¹„ì¤‘']) and pd.isna(row['60ëŒ€ì´ìƒ_ë¹„ì¤‘']):
                    return None

                # NaNì„ 0ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë¹„êµ
                gen_2030 = row['2030ì„¸ëŒ€_ë¹„ì¤‘'] if pd.notna(row['2030ì„¸ëŒ€_ë¹„ì¤‘']) else 0
                gen_4050 = row['4050ì„¸ëŒ€_ë¹„ì¤‘'] if pd.notna(row['4050ì„¸ëŒ€_ë¹„ì¤‘']) else 0
                gen_60 = row['60ëŒ€ì´ìƒ_ë¹„ì¤‘'] if pd.notna(row['60ëŒ€ì´ìƒ_ë¹„ì¤‘']) else 0

                # ëª¨ë‘ 0ì´ë©´ None
                if gen_2030 == 0 and gen_4050 == 0 and gen_60 == 0:
                    return None

                # ìµœëŒ€ê°’ì„ ê°€ì§„ ì„¸ëŒ€ ë°˜í™˜
                max_val = max(gen_2030, gen_4050, gen_60)
                if gen_2030 == max_val:
                    return '2030'
                elif gen_4050 == max_val:
                    return '4050'
                else:
                    return '60+'

            self.merged_data['ì£¼ë ¥ì„¸ëŒ€'] = self.merged_data.apply(get_main_generation, axis=1)

            # None ê°’ í†µê³„ ì¶œë ¥
            null_count = self.merged_data['ì£¼ë ¥ì„¸ëŒ€'].isna().sum()
            if null_count > 0:
                print(f"  âš ï¸ ì£¼ë ¥ì„¸ëŒ€ ì •ë³´ ì—†ìŒ: {null_count:,}ê±´ (ì „ì²´ì˜ {null_count/len(self.merged_data)*100:.1f}%)")
                print(f"     â†’ ì„¸ëŒ€ë³„ ê³ ê° ë°ì´í„°ê°€ ì—†ëŠ” ê°€ë§¹ì ì…ë‹ˆë‹¤.")

        # 4-4. ê³ ê° ë‹¤ì–‘ì„± ì§€ìˆ˜
        if demographic_cols:
            demographic_data = self.merged_data[demographic_cols].fillna(0)

            def calculate_entropy(row):
                probs = row / (row.sum() + 1e-10)
                probs = probs[probs > 0]
                return -np.sum(probs * np.log2(probs + 1e-10))

            self.merged_data['ê³ ê°ë‹¤ì–‘ì„±ì§€ìˆ˜'] = demographic_data.apply(calculate_entropy, axis=1)

        # === 5. ì‹œê³„ì—´ íŠ¹ì„± (ë§¤ì¶œ, ì´ìš©ê±´ìˆ˜, ê³ ê° ìˆ˜) ===
        print("  ğŸ“ˆ ì‹œê³„ì—´ íŠ¹ì„± ìƒì„± ì¤‘...")

        key_metrics = ['RC_M1_SAA_num', 'RC_M1_TO_UE_CT_num', 'RC_M1_UE_CUS_CN_num', 'RC_M1_AV_NP_AT_num']

        for col in key_metrics:
            if col in self.merged_data.columns:
                # ë³€í™”ìœ¨ (1M, 3M, 6M)
                self.merged_data[f'{col}_ë³€í™”ìœ¨_1M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].pct_change(1) * 100

                self.merged_data[f'{col}_ë³€í™”ìœ¨_3M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].pct_change(3) * 100

                self.merged_data[f'{col}_ë³€í™”ìœ¨_6M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].pct_change(6) * 100

                # ì´ë™í‰ê·  (3M, 6M)
                self.merged_data[f'{col}_MA3'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].transform(
                        lambda x: x.rolling(window=3, min_periods=1).mean()
                    )

                self.merged_data[f'{col}_MA6'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].transform(
                        lambda x: x.rolling(window=6, min_periods=1).mean()
                    )

                # ì¶”ì„¸ (ë³€í™”ìœ¨ì˜ ì´ë™í‰ê· )
                change_col = f'{col}_ë³€í™”ìœ¨_1M'
                if change_col in self.merged_data.columns:
                    self.merged_data[f'{col}_ì¶”ì„¸3M'] = \
                        self.merged_data.groupby('ENCODED_MCT')[change_col].transform(
                            lambda x: x.rolling(window=3, min_periods=1).mean()
                        )

                # ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
                self.merged_data[f'{col}_STD3M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].transform(
                        lambda x: x.rolling(window=3, min_periods=1).std()
                    )

                # ì—°ì† í•˜ë½ ê°œì›” ìˆ˜
                self.merged_data[f'{col}_í•˜ë½ì—¬ë¶€'] = (
                    self.merged_data[f'{col}_ë³€í™”ìœ¨_1M'] < -5
                ).astype(int)

                def count_consecutive(group):
                    result = []
                    count = 0
                    for val in group:
                        if val == 1:
                            count += 1
                        else:
                            count = 0
                        result.append(count)
                    return pd.Series(result, index=group.index)

                self.merged_data[f'{col}_ì—°ì†í•˜ë½'] = \
                    self.merged_data.groupby('ENCODED_MCT')[f'{col}_í•˜ë½ì—¬ë¶€'].apply(
                        count_consecutive
                    ).values

        # === 6. ì„ëŒ€ë£Œ íŠ¹ì„± (rental) ===
        print("  ğŸ¢ ì„ëŒ€ë£Œ íŠ¹ì„± ìƒì„± ì¤‘...")

        if 'ì „ì²´(ë‹¨ìœ„:ì›/í‰)' in self.merged_data.columns:
            # ì„ëŒ€ë£Œ ë³€í™”ìœ¨
            self.merged_data['ì„ëŒ€ë£Œ_ë³€í™”_3M'] = \
                self.merged_data.groupby('ENCODED_MCT')['ì „ì²´(ë‹¨ìœ„:ì›/í‰)'].pct_change(3) * 100

            # ì„ëŒ€ë£Œ ëŒ€ë¹„ ë§¤ì¶œ íš¨ìœ¨
            if 'RC_M1_SAA_num' in self.merged_data.columns:
                self.merged_data['ì„ëŒ€ë£ŒëŒ€ë¹„ë§¤ì¶œíš¨ìœ¨'] = \
                    self.merged_data['RC_M1_SAA_num'] / (
                        self.merged_data['ì „ì²´(ë‹¨ìœ„:ì›/í‰)'] / 10000 + 1
                    )

        # === 7. ìœ ë™ì¸êµ¬ íŠ¹ì„± (flow) ===
        print("  ğŸ‘¥ ìœ ë™ì¸êµ¬ íŠ¹ì„± ìƒì„± ì¤‘...")

        if 'ìœ ë™ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)' in self.merged_data.columns:
            # ìœ ë™ì¸êµ¬ ë³€í™”ìœ¨
            self.merged_data['ìœ ë™ì¸êµ¬_ë³€í™”_3M'] = \
                self.merged_data.groupby('ENCODED_MCT')['ìœ ë™ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)'].pct_change(3) * 100

            # ìœ ë™ì¸êµ¬ ëŒ€ë¹„ ë§¤ì¶œ
            if 'RC_M1_SAA_num' in self.merged_data.columns:
                self.merged_data['ìœ ë™ì¸êµ¬ëŒ€ë¹„ë§¤ì¶œ'] = \
                    self.merged_data['RC_M1_SAA_num'] / (
                        self.merged_data['ìœ ë™ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)'] / 1000 + 1
                    )

        # ì£¼ê±°/ì§ì¥ ì¸êµ¬ ë¹„ìœ¨
        if 'ì£¼ê±°ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)' in self.merged_data.columns and 'ì§ì¥ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)' in self.merged_data.columns:
            total_pop = (
                self.merged_data['ì£¼ê±°ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)'] +
                self.merged_data['ì§ì¥ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)'] + 1
            )
            self.merged_data['ì£¼ê±°ì¸êµ¬_ë¹„ìœ¨'] = self.merged_data['ì£¼ê±°ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)'] / total_pop * 100
            self.merged_data['ì§ì¥ì¸êµ¬_ë¹„ìœ¨'] = self.merged_data['ì§ì¥ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)'] / total_pop * 100

        # === 8. ê°€ë§¹ì  ì •ë³´ (set1) íŠ¹ì„± ===
        print("  ğŸª ê°€ë§¹ì  ì •ë³´ íŠ¹ì„± ìƒì„± ì¤‘...")

        # ê°œì—… ê²½ê³¼ ì¼ìˆ˜
        if 'ARE_D' in self.merged_data.columns:
            self.merged_data['ARE_D'] = pd.to_datetime(
                self.merged_data['ARE_D'], format='%Y%m%d', errors='coerce'
            )
            self.merged_data['ê°œì—…ê²½ê³¼ì¼'] = (
                self.merged_data['TA_YM'] - self.merged_data['ARE_D']
            ).dt.days

        print(f"âœ“ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(self.merged_data.columns)}ê°œ ì»¬ëŸ¼\n")

    def create_target_variable(self):
        """íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ë¯¸ë˜ ìœ„í—˜ ì˜ˆì¸¡)"""
        print("ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘...")

        # ë¯¸ë˜ 3ê°œì›” í›„ ë§¤ì¶œ í•˜ë½ ì—¬ë¶€ë¡œ ë ˆì´ë¸” ìƒì„±
        self.merged_data = self.merged_data.sort_values(['ENCODED_MCT', 'TA_YM'])

        # 3ê°œì›” í›„ ë§¤ì¶œ ë³€í™”ìœ¨
        self.merged_data['ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”'] = \
            self.merged_data.groupby('ENCODED_MCT')['RC_M1_SAA_num'].shift(-3)

        self.merged_data['ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”ìœ¨'] = (
            (self.merged_data['ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”'] - self.merged_data['RC_M1_SAA_num']) /
            (self.merged_data['RC_M1_SAA_num'] + 1)
        ) * 100

        # íƒ€ê²Ÿ ë ˆì´ë¸” ì •ì˜ (4ê°œ í´ë˜ìŠ¤ ê· í˜•ìˆê²Œ)
        conditions = [
            self.merged_data['ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”ìœ¨'] > 10,                          # 0: ì•ˆì „ (ì„±ì¥)
            self.merged_data['ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”ìœ¨'].between(-10, 10),            # 1: ì£¼ì˜ (ì•ˆì •)
            self.merged_data['ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”ìœ¨'].between(-30, -10, inclusive='left'),  # 2: ê²½ê³  (í•˜ë½)
            self.merged_data['ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”ìœ¨'] <= -30                        # 3: ìœ„í—˜ (ê¸‰ë½)
        ]

        self.merged_data['ê²½ë³´ë ˆë²¨'] = np.select(
            conditions,
            [0, 1, 2, 3],
            default=1  # ê¸°ë³¸ê°’ì€ ì£¼ì˜
        )

        # ì¶”ê°€ ìœ„í—˜ ìš”ì¸ ë°˜ì˜
        # ì—°ì† í•˜ë½ì´ ìˆìœ¼ë©´ ë ˆë²¨ ìƒí–¥ ì¡°ì •
        if 'RC_M1_SAA_num_ì—°ì†í•˜ë½' in self.merged_data.columns:
            # ì—°ì† 3ê°œì›” ì´ìƒ í•˜ë½ + í˜„ì¬ ë ˆë²¨ì´ ì£¼ì˜ ì´í•˜ë©´ -> ê²½ê³ ë¡œ
            self.merged_data.loc[
                (self.merged_data['RC_M1_SAA_num_ì—°ì†í•˜ë½'] >= 3) &
                (self.merged_data['ê²½ë³´ë ˆë²¨'] <= 1),
                'ê²½ë³´ë ˆë²¨'
            ] = 2

            # ì—°ì† 5ê°œì›” ì´ìƒ í•˜ë½ + í˜„ì¬ ë ˆë²¨ì´ ê²½ê³  ì´í•˜ë©´ -> ìœ„í—˜ìœ¼ë¡œ
            self.merged_data.loc[
                (self.merged_data['RC_M1_SAA_num_ì—°ì†í•˜ë½'] >= 5) &
                (self.merged_data['ê²½ë³´ë ˆë²¨'] <= 2),
                'ê²½ë³´ë ˆë²¨'
            ] = 3

        # ê³ ê° ìˆ˜ ê¸‰ê°ë„ ìœ„í—˜ ìš”ì¸
        if 'RC_M1_UE_CUS_CN_num_ë³€í™”ìœ¨_3M' in self.merged_data.columns:
            self.merged_data.loc[
                (self.merged_data['RC_M1_UE_CUS_CN_num_ë³€í™”ìœ¨_3M'] < -40) &
                (self.merged_data['ê²½ë³´ë ˆë²¨'] <= 2),
                'ê²½ë³´ë ˆë²¨'
            ] = 3

        # ë¯¸ë˜ ë°ì´í„°ê°€ ì—†ëŠ” í–‰ ì œê±° (ë§ˆì§€ë§‰ 3ê°œì›”)
        self.merged_data = self.merged_data[self.merged_data['ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”ìœ¨'].notna()]

        print(f"âœ“ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ")
        print(f"  ë ˆì´ë¸” ë¶„í¬:")
        for level in range(4):
            count = (self.merged_data['ê²½ë³´ë ˆë²¨'] == level).sum()
            pct = count / len(self.merged_data) * 100
            print(f"    {self.WARNING_LEVELS[level]['emoji']} {self.WARNING_LEVELS[level]['name']}: {count:,}ê±´ ({pct:.1f}%)")
        print()

    def prepare_ml_features(self):
        """ë¨¸ì‹ ëŸ¬ë‹ìš© íŠ¹ì„± ì¤€ë¹„"""
        print("ğŸ”¨ ML íŠ¹ì„± ì¤€ë¹„ ì¤‘...")

        # ì œì™¸í•  ì»¬ëŸ¼
        exclude_cols = [
            'ENCODED_MCT', 'TA_YM', 'MCT_BSE_AR', 'MCT_NM', 'MCT_BRD_NUM', 'ARE_D',
            '__filled_flag__', '__fill_method__', '__impute_source__',
            'ê²½ë³´ë ˆë²¨', 'LEGAL_DONG', 'í–‰ì •êµ¬ì—­', 'í–‰ì êµ¬ì—­', 'MCT_SIGUNGU_NM',
            'ê¸°ê°„', 'ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”', 'ë¯¸ë˜_3M_ë§¤ì¶œë³€í™”ìœ¨',
            # ì›ë³¸ ë²”ì£¼í˜• ì»¬ëŸ¼ (ì¸ì½”ë”© ì „)
            'MCT_OPE_MS_CN', 'RC_M1_SAA', 'RC_M1_TO_UE_CT', 'RC_M1_UE_CUS_CN',
            'RC_M1_AV_NP_AT', 'APV_CE_RAT',
            # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê±°ì£¼/ì§ì¥/ìœ ì… ì»¬ëŸ¼ (ì´ë¯¸ ì‚­ì œë˜ì—ˆì§€ë§Œ ëª…ì‹œ)
            'RC_M1_SHC_RSD_UE_CLN_RAT', 'RC_M1_SHC_WP_UE_CLN_RAT', 'RC_M1_SHC_FLP_UE_CLN_RAT'
        ]

        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_cols = ['HPSN_MCT_ZCD_NM', 'HPSN_MCT_BZN_CD_NM', 'ì£¼ë ¥ì„¸ëŒ€', 'ì›”', 'ë¶„ê¸°', 'ì—°ë„']

        for col in categorical_cols:
            if col in self.merged_data.columns:
                le = LabelEncoder()
                self.merged_data[f'{col}_encoded'] = le.fit_transform(
                    self.merged_data[col].fillna('Unknown').astype(str)
                )
                self.label_encoders[col] = le
                exclude_cols.append(col)  # ì›ë³¸ ì œì™¸

        # íŠ¹ì„± ì„ íƒ
        all_cols = set(self.merged_data.columns)
        exclude_set = set(exclude_cols)
        potential_features = all_cols - exclude_set

        self.feature_cols = []
        for col in potential_features:
            if self.merged_data[col].dtype in ['int64', 'float64', 'int32', 'float32']:
                # ê²°ì¸¡ì¹˜ ë¹„ìœ¨ í™•ì¸
                missing_rate = self.merged_data[col].isna().sum() / len(self.merged_data)
                if missing_rate < 0.9:  # 90% ì´ìƒ ê²°ì¸¡ ì œì™¸
                    self.feature_cols.append(col)

        print(f"âœ“ ì„ íƒëœ íŠ¹ì„±: {len(self.feature_cols)}ê°œ")

        # íŠ¹ì„± ê·¸ë£¹ë³„ ê°œìˆ˜
        feature_groups = {
            'ë§¤ì¶œ/ìš´ì˜': [f for f in self.feature_cols if any(x in f for x in ['SAA', 'TO_UE', 'CUS', 'OPE', 'AV_NP'])],
            'ì„¸ëŒ€ë³„': [f for f in self.feature_cols if any(x in f for x in ['MAL', 'FME', 'ì„¸ëŒ€', 'ê³ ê°ë‹¤ì–‘ì„±'])],
            'ì‹œê³„ì—´': [f for f in self.feature_cols if any(x in f for x in ['ë³€í™”ìœ¨', 'MA', 'ì¶”ì„¸', 'STD', 'ì—°ì†'])],
            'ì„ëŒ€ë£Œ': [f for f in self.feature_cols if 'ì„ëŒ€ë£Œ' in f],
            'ìœ ë™ì¸êµ¬': [f for f in self.feature_cols if any(x in f for x in ['ìœ ë™ì¸êµ¬', 'ì£¼ê±°ì¸êµ¬', 'ì§ì¥ì¸êµ¬'])],
            'ê¸°íƒ€': []
        }

        assigned = set()
        for group in feature_groups.values():
            assigned.update(group)

        feature_groups['ê¸°íƒ€'] = [f for f in self.feature_cols if f not in assigned]

        print(f"\n  íŠ¹ì„± ê·¸ë£¹ë³„ ë¶„í¬:")
        for group_name, features in feature_groups.items():
            if features:
                print(f"    {group_name}: {len(features)}ê°œ")
        print()

    def train_model(self):
        """LightGBM ëª¨ë¸ í•™ìŠµ"""
        print("=" * 80)
        print("ğŸš€ LightGBM ëª¨ë¸ í•™ìŠµ")
        print("=" * 80)

        # í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ìš´ì˜ 3ê°œì›” ì´ìƒ)
        train_data = self.merged_data[self.merged_data['ìš´ì˜ê°œì›”ìˆ˜'] >= 3].copy()

        X = train_data[self.feature_cols].fillna(0)
        y = train_data['ê²½ë³´ë ˆë²¨']

        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ í™•ì¸
        unique_classes = sorted(y.unique())
        num_classes = len(unique_classes)

        print(f"âœ“ ì‹¤ì œ í´ë˜ìŠ¤ ìˆ˜: {num_classes}ê°œ ({unique_classes})")

        # ì‹œê³„ì—´ ë¶„í•  (ìµœê·¼ 20%ë¥¼ í…ŒìŠ¤íŠ¸)
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

        print(f"âœ“ í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê±´")
        print(f"âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê±´")

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¶„í¬
        print(f"\n  í•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
        for cls in unique_classes:
            count = (y_train == cls).sum()
            print(f"    í´ë˜ìŠ¤ {cls}: {count:,}ê±´ ({count/len(y_train)*100:.1f}%)")

        print(f"\n  í…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
        for cls in unique_classes:
            count = (y_test == cls).sum()
            print(f"    í´ë˜ìŠ¤ {cls}: {count:,}ê±´ ({count/len(y_test)*100:.1f}%)")
        print()

        # LightGBM ë°ì´í„°ì…‹
        lgb_train = lgb.Dataset(X_train, y_train)
        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)

        # íŒŒë¼ë¯¸í„°
        params = {
            'objective': 'multiclass',
            'num_class': num_classes,  # ì‹¤ì œ í´ë˜ìŠ¤ ìˆ˜ë¡œ ì„¤ì •
            'metric': 'multi_logloss',
            'boosting_type': 'gbdt',
            'num_leaves': 40,
            'learning_rate': 0.03,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1,
            'max_depth': 8,
            'min_child_samples': 30,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1
        }

        # í•™ìŠµ
        print("ğŸ”„ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        self.model = lgb.train(
            params,
            lgb_train,
            num_boost_round=1000,
            valid_sets=[lgb_train, lgb_eval],
            valid_names=['train', 'valid'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=100),
                lgb.log_evaluation(period=100)
            ]
        )

        print("\nâœ“ í•™ìŠµ ì™„ë£Œ!\n")

        # í‰ê°€
        y_pred = self.model.predict(X_test, num_iteration=self.model.best_iteration)
        y_pred_class = np.argmax(y_pred, axis=1)

        print("=" * 80)
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
        print("=" * 80)
        print("\n[ë¶„ë¥˜ ë¦¬í¬íŠ¸]")

        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ì— ëŒ€í•œ ë ˆì´ë¸”ë§Œ ì‚¬ìš©
        target_names = [f"{self.WARNING_LEVELS[i]['emoji']} {self.WARNING_LEVELS[i]['name']}"
                        for i in unique_classes]

        print(classification_report(
            y_test, y_pred_class,
            labels=unique_classes,
            target_names=target_names,
            zero_division=0
        ))

        # ì „ì²´ ë°ì´í„° ì˜ˆì¸¡
        print("ğŸ”® ì „ì²´ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...")
        X_all = self.merged_data[self.feature_cols].fillna(0)
        y_pred_all = self.model.predict(X_all, num_iteration=self.model.best_iteration)

        self.merged_data['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'] = np.argmax(y_pred_all, axis=1)

        # ê° í´ë˜ìŠ¤ë³„ í™•ë¥  ì €ì¥
        for i in range(num_classes):
            self.merged_data[f'ì˜ˆì¸¡_í™•ë¥ _{i}'] = y_pred_all[:, i]

        # 4ê°œ í´ë˜ìŠ¤ê°€ ì•„ë‹Œ ê²½ìš° ë‚˜ë¨¸ì§€ í™•ë¥  ì»¬ëŸ¼ë„ 0ìœ¼ë¡œ ì±„ìš°ê¸°
        for i in range(num_classes, 4):
            self.merged_data[f'ì˜ˆì¸¡_í™•ë¥ _{i}'] = 0.0

        # ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜ (í™•ë¥  ê°€ì¤‘ í‰ê· )
        # ê° í´ë˜ìŠ¤ë³„ í™•ë¥ ì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•´ì„œ í•©ì‚°
        risk_score = self.merged_data['ì˜ˆì¸¡_í™•ë¥ _0'] * 0

        if 'ì˜ˆì¸¡_í™•ë¥ _1' in self.merged_data.columns:
            risk_score += self.merged_data['ì˜ˆì¸¡_í™•ë¥ _1'] * 33
        if 'ì˜ˆì¸¡_í™•ë¥ _2' in self.merged_data.columns:
            risk_score += self.merged_data['ì˜ˆì¸¡_í™•ë¥ _2'] * 66
        if 'ì˜ˆì¸¡_í™•ë¥ _3' in self.merged_data.columns:
            risk_score += self.merged_data['ì˜ˆì¸¡_í™•ë¥ _3'] * 100

        self.merged_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'] = risk_score

        print("âœ“ ì˜ˆì¸¡ ì™„ë£Œ!\n")

        return X_test, y_test, y_pred

    def visualize_feature_importance(self, save_path='ml_feature_importance.png', top_n=40):
        """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
        print("ğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” ì¤‘...")

        fig, ax = plt.subplots(1, 1, figsize=(14, 12))
        fig.suptitle('LightGBM íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ (Gain ê¸°ì¤€)', fontsize=18, fontweight='bold')

        importance = self.model.feature_importance(importance_type='gain')
        indices = np.argsort(importance)[::-1][:top_n]

        # íŠ¹ì„± ê·¸ë£¹ë³„ ìƒ‰ìƒ
        colors = []
        for idx in indices:
            feat_name = self.feature_cols[idx]
            if any(x in feat_name for x in ['ì„¸ëŒ€', 'MAL', 'FME', 'ê³ ê°ë‹¤ì–‘ì„±']):
                colors.append('#FF6B6B')  # ë¹¨ê°• - ì„¸ëŒ€ë³„
            elif any(x in feat_name for x in ['ë³€í™”ìœ¨', 'MA', 'ì¶”ì„¸', 'STD', 'ì—°ì†']):
                colors.append('#4ECDC4')  # ì²­ë¡ - ì‹œê³„ì—´
            elif 'ì„ëŒ€ë£Œ' in feat_name:
                colors.append('#FFE66D')  # ë…¸ë‘ - ì„ëŒ€ë£Œ
            elif any(x in feat_name for x in ['ìœ ë™ì¸êµ¬', 'ì£¼ê±°ì¸êµ¬', 'ì§ì¥ì¸êµ¬']):
                colors.append('#95E1D3')  # ë¯¼íŠ¸ - ì¸êµ¬
            else:
                colors.append('#A8DADC')  # íšŒì²­ - ê¸°íƒ€

        bars = ax.barh(range(top_n), importance[indices], color=colors, edgecolor='black', linewidth=0.5)
        ax.set_yticks(range(top_n))
        ax.set_yticklabels([self.feature_cols[i] for i in indices], fontsize=9)
        ax.invert_yaxis()
        ax.set_xlabel('ì¤‘ìš”ë„ (Gain)', fontsize=12, fontweight='bold')
        ax.set_title(f'Top {top_n} íŠ¹ì„± ì¤‘ìš”ë„', fontsize=14, fontweight='bold', pad=15)
        ax.grid(axis='x', alpha=0.3, linestyle='--')

        # ë²”ë¡€
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#FF6B6B', label='ì„¸ëŒ€ë³„ íŠ¹ì„±'),
            Patch(facecolor='#4ECDC4', label='ì‹œê³„ì—´ íŠ¹ì„±'),
            Patch(facecolor='#FFE66D', label='ì„ëŒ€ë£Œ íŠ¹ì„±'),
            Patch(facecolor='#95E1D3', label='ìœ ë™ì¸êµ¬ íŠ¹ì„±'),
            Patch(facecolor='#A8DADC', label='ê¸°íƒ€')
        ]
        ax.legend(handles=legend_elements, loc='lower right', fontsize=10)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def visualize_generation_analysis(self, save_path='generation_analysis.png'):
        """ì„¸ëŒ€ë³„ ë§¤ì¶œ ë¶„ì„ ì‹œê°í™”"""
        print("ğŸ“Š ì„¸ëŒ€ë³„ ë¶„ì„ ì‹œê°í™” ì¤‘...")

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ì„¸ëŒ€ë³„ ë§¤ì¶œ ë³€í™” ë¶„ì„ (2023-01 ~ 2024-12)', fontsize=18, fontweight='bold', y=0.995)

        # 1. ì›”ë³„ ì„¸ëŒ€ ë¹„ì¤‘ ì¶”ì´
        ax1 = axes[0, 0]
        monthly_gen = self.merged_data.groupby('TA_YM')[
            ['2030ì„¸ëŒ€_ë¹„ì¤‘', '4050ì„¸ëŒ€_ë¹„ì¤‘', '60ëŒ€ì´ìƒ_ë¹„ì¤‘']
        ].mean()

        ax1.plot(monthly_gen.index, monthly_gen['2030ì„¸ëŒ€_ë¹„ì¤‘'],
                marker='o', linewidth=2.5, label='2030ì„¸ëŒ€', color='#FF6B6B')
        ax1.plot(monthly_gen.index, monthly_gen['4050ì„¸ëŒ€_ë¹„ì¤‘'],
                marker='s', linewidth=2.5, label='4050ì„¸ëŒ€', color='#4ECDC4')
        ax1.plot(monthly_gen.index, monthly_gen['60ëŒ€ì´ìƒ_ë¹„ì¤‘'],
                marker='^', linewidth=2.5, label='60ëŒ€ ì´ìƒ', color='#95E1D3')

        ax1.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
        ax1.set_ylabel('í‰ê·  ë¹„ì¤‘ (%)', fontsize=11, fontweight='bold')
        ax1.set_title('ì›”ë³„ ì„¸ëŒ€ ë¹„ì¤‘ ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
        ax1.legend(fontsize=10, loc='best')
        ax1.grid(True, alpha=0.3, linestyle='--')
        ax1.tick_params(axis='x', rotation=45)

        # 2. ì£¼ë ¥ì„¸ëŒ€ë³„ ê°€ë§¹ì  ìˆ˜
        ax2 = axes[0, 1]
        latest_data = self.merged_data[self.merged_data['TA_YM'] == self.merged_data['TA_YM'].max()]

        if 'ì£¼ë ¥ì„¸ëŒ€' in latest_data.columns:
            # NaN ê°’ì„ 'ì •ë³´ì—†ìŒ'ìœ¼ë¡œ í‘œì‹œ
            gen_counts = latest_data['ì£¼ë ¥ì„¸ëŒ€'].fillna('ì •ë³´ì—†ìŒ').value_counts()

            # ì›í•˜ëŠ” ìˆœì„œë¡œ ì •ë ¬: 2030, 4050, ì •ë³´ì—†ìŒ, 60+
            order = ['2030', '4050', '60+', 'ì •ë³´ì—†ìŒ']
            gen_counts = gen_counts.reindex([g for g in order if g in gen_counts.index])

            colors_gen = {
                '2030': '#FF6B6B',
                '4050': '#4ECDC4',
                '60+': '#95E1D3',
                'ì •ë³´ì—†ìŒ': '#DDDDDD'
            }
            colors_list = [colors_gen.get(g, '#CCCCCC') for g in gen_counts.index]

            bars = ax2.bar(range(len(gen_counts)), gen_counts.values,
                          color=colors_list, alpha=0.7, edgecolor='black', linewidth=2)
            ax2.set_xticks(range(len(gen_counts)))
            ax2.set_xticklabels(gen_counts.index, fontsize=11)
            ax2.set_ylabel('ê°€ë§¹ì  ìˆ˜', fontsize=11, fontweight='bold')
            ax2.set_title('ì£¼ë ¥ ì„¸ëŒ€ë³„ ê°€ë§¹ì  ë¶„í¬', fontsize=13, fontweight='bold', pad=10)
            ax2.grid(axis='y', alpha=0.3, linestyle='--')

            for bar in bars:
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height):,}',
                        ha='center', va='bottom', fontsize=10, fontweight='bold')

        # 3. ì„¸ëŒ€ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜
        ax3 = axes[1, 0]
        if 'ì£¼ë ¥ì„¸ëŒ€' in latest_data.columns and 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜' in latest_data.columns:
            # NaN ê°’ì„ 'ì •ë³´ì—†ìŒ'ìœ¼ë¡œ ë³€í™˜ í›„ ê·¸ë£¹í™”
            latest_data_copy = latest_data.copy()
            latest_data_copy['ì£¼ë ¥ì„¸ëŒ€'] = latest_data_copy['ì£¼ë ¥ì„¸ëŒ€'].fillna('ì •ë³´ì—†ìŒ')
            gen_risk = latest_data_copy.groupby('ì£¼ë ¥ì„¸ëŒ€')['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].mean()

            # ì›í•˜ëŠ” ìˆœì„œë¡œ ì •ë ¬: 2030, 4050, ì •ë³´ì—†ìŒ, 60+ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
            order = ['ì •ë³´ì—†ìŒ', '60+', '4050', '2030']
            gen_risk = gen_risk.reindex([g for g in order if g in gen_risk.index])

            bars = ax3.barh(range(len(gen_risk)), gen_risk.values,
                           color='coral', alpha=0.7, edgecolor='black')
            ax3.set_yticks(range(len(gen_risk)))
            ax3.set_yticklabels(gen_risk.index, fontsize=11)
            ax3.set_xlabel('í‰ê·  ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜', fontsize=11, fontweight='bold')
            ax3.set_title('ì£¼ë ¥ ì„¸ëŒ€ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜', fontsize=13, fontweight='bold', pad=10)
            ax3.grid(axis='x', alpha=0.3, linestyle='--')

            # ìœ„í—˜ êµ¬ê°„ í‘œì‹œ
            ax3.axvline(x=33, color='yellow', linestyle='--', linewidth=1.5, alpha=0.7)
            ax3.axvline(x=66, color='orange', linestyle='--', linewidth=1.5, alpha=0.7)

            for i, bar in enumerate(bars):
                width = bar.get_width()
                ax3.text(width + 1, bar.get_y() + bar.get_height()/2.,
                        f'{width:.1f}',
                        ha='left', va='center', fontsize=10, fontweight='bold')

        # 4. ì„¸ëŒ€ ë³€í™”ì™€ ë§¤ì¶œ ë³€í™”ì˜ ê´€ê³„
        ax4 = axes[1, 1]
        if '2030ì„¸ëŒ€_ë¹„ì¤‘_ë³€í™”_3M' in self.merged_data.columns and 'RC_M1_SAA_num_ë³€í™”ìœ¨_3M' in self.merged_data.columns:
            sample_data = self.merged_data[
                self.merged_data['2030ì„¸ëŒ€_ë¹„ì¤‘_ë³€í™”_3M'].notna() &
                self.merged_data['RC_M1_SAA_num_ë³€í™”ìœ¨_3M'].notna()
            ].sample(min(1000, len(self.merged_data)))

            scatter = ax4.scatter(
                sample_data['2030ì„¸ëŒ€_ë¹„ì¤‘_ë³€í™”_3M'],
                sample_data['RC_M1_SAA_num_ë³€í™”ìœ¨_3M'],
                c=sample_data['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'],
                cmap='RdYlGn_r',
                alpha=0.6,
                s=30,
                edgecolors='black',
                linewidth=0.5
            )

            ax4.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.5)
            ax4.axvline(x=0, color='black', linestyle='-', linewidth=1, alpha=0.5)
            ax4.set_xlabel('2030ì„¸ëŒ€ ë¹„ì¤‘ ë³€í™” (3ê°œì›”, %p)', fontsize=11, fontweight='bold')
            ax4.set_ylabel('ë§¤ì¶œ ë³€í™”ìœ¨ (3ê°œì›”, %)', fontsize=11, fontweight='bold')
            ax4.set_title('2030ì„¸ëŒ€ ë¹„ì¤‘ ë³€í™” vs ë§¤ì¶œ ë³€í™”', fontsize=13, fontweight='bold', pad=10)
            ax4.grid(True, alpha=0.3, linestyle='--')

            cbar = plt.colorbar(scatter, ax=ax4)
            cbar.set_label('ì˜ˆì¸¡ ê²½ë³´ ë ˆë²¨', fontsize=10)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def visualize_merchant_detail(self, merchant_id, save_path='merchant_detail.png'):
        """ê°€ë§¹ì ë³„ ìƒì„¸ ë¶„ì„ ì‹œê°í™” (ë§¤ì¶œ/ì„¸ëŒ€/ìœ„í—˜ì„± ì¶”ì´)"""
        print(f"ğŸ” ê°€ë§¹ì  ìƒì„¸ ë¶„ì„: {merchant_id}")

        merchant_data = self.merged_data[self.merged_data['ENCODED_MCT'] == merchant_id].copy()
        merchant_data = merchant_data.sort_values('TA_YM')

        if len(merchant_data) == 0:
            print(f"âŒ í•´ë‹¹ ê°€ë§¹ì  ë°ì´í„° ì—†ìŒ: {merchant_id}")
            return

        fig, axes = plt.subplots(2, 3, figsize=(20, 12))

        # ê°€ë§¹ì  ì •ë³´
        latest = merchant_data.iloc[-1]
        mct_name = latest.get('MCT_NM', 'N/A')
        mct_type = latest.get('HPSN_MCT_BZN_CD_NM', 'N/A')

        fig.suptitle(f'ê°€ë§¹ì  ìƒì„¸ ë¶„ì„\n{mct_name} ({mct_type})',
                     fontsize=18, fontweight='bold', y=0.98)

        # 1. ë§¤ì¶œ ë³€í™” ì¶”ì´
        ax1 = axes[0, 0]
        ax1_twin = ax1.twinx()

        # ë§¤ì¶œ ìˆ˜ì¤€ (ì™¼ìª½ ì¶•)
        l1 = ax1.plot(merchant_data['TA_YM'], merchant_data['RC_M1_SAA_num'],
                     marker='o', linewidth=2.5, markersize=6, color='#2E86AB', label='ë§¤ì¶œ ìˆ˜ì¤€')
        ax1.fill_between(merchant_data['TA_YM'], merchant_data['RC_M1_SAA_num'],
                         alpha=0.2, color='#2E86AB')

        # ë§¤ì¶œ ë³€í™”ìœ¨ (ì˜¤ë¥¸ìª½ ì¶•)
        l2 = ax1_twin.plot(merchant_data['TA_YM'], merchant_data['RC_M1_SAA_num_ë³€í™”ìœ¨_3M'],
                          marker='s', linewidth=2, markersize=5, color='#E63946',
                          label='3ê°œì›” ë³€í™”ìœ¨', linestyle='--')
        ax1_twin.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.3)

        ax1.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
        ax1.set_ylabel('ë§¤ì¶œ ìˆ˜ì¤€ (ë°±ë¶„ìœ„)', fontsize=11, fontweight='bold', color='#2E86AB')
        ax1_twin.set_ylabel('ë³€í™”ìœ¨ (%)', fontsize=11, fontweight='bold', color='#E63946')
        ax1.tick_params(axis='y', labelcolor='#2E86AB')
        ax1_twin.tick_params(axis='y', labelcolor='#E63946')
        ax1.tick_params(axis='x', rotation=45)

        lines = l1 + l2
        labels = [l.get_label() for l in lines]
        ax1.legend(lines, labels, loc='upper left', fontsize=10)
        ax1.set_title('ë§¤ì¶œ ë³€í™” ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
        ax1.grid(True, alpha=0.3, linestyle='--')

        # 2. ë‚¨ì„± ì„¸ëŒ€ë³„ ë¹„ì¤‘ ë³€í™” ì¶”ì´
        ax2 = axes[0, 1]
        male_age_cols = ['M12_MAL_1020_RAT', 'M12_MAL_30_RAT', 'M12_MAL_40_RAT',
                        'M12_MAL_50_RAT', 'M12_MAL_60_RAT']
        male_age_labels = ['ğŸ‘¨ 10-20ëŒ€', 'ğŸ‘¨ 30ëŒ€', 'ğŸ‘¨ 40ëŒ€', 'ğŸ‘¨ 50ëŒ€', 'ğŸ‘¨ 60ëŒ€+']
        male_colors = ['#FF6B6B', '#FF8E53', '#FFA94D', '#FFD93D', '#6BCB77']

        for col, label, color in zip(male_age_cols, male_age_labels, male_colors):
            if col in merchant_data.columns:
                data = merchant_data[col].fillna(0)
                ax2.plot(merchant_data['TA_YM'], data,
                        marker='o', linewidth=2, label=label, color=color, alpha=0.8)

        ax2.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
        ax2.set_ylabel('ë‚¨ì„± ê³ ê° ë¹„ì¤‘ (%)', fontsize=11, fontweight='bold')
        ax2.set_title('ğŸ‘¨ ë‚¨ì„± ê³ ê° - ì—°ë ¹ëŒ€ë³„ ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
        ax2.legend(fontsize=9, loc='best', ncol=2)
        ax2.grid(True, alpha=0.3, linestyle='--')
        ax2.tick_params(axis='x', rotation=45)
        ax2.set_ylim(0, max(100, merchant_data[male_age_cols].max().max() * 1.1) if any(col in merchant_data.columns for col in male_age_cols) else 100)

        # 3. ì—¬ì„± ì„¸ëŒ€ë³„ ë¹„ì¤‘ ë³€í™” ì¶”ì´
        ax3 = axes[0, 2]
        female_age_cols = ['M12_FME_1020_RAT', 'M12_FME_30_RAT', 'M12_FME_40_RAT',
                          'M12_FME_50_RAT', 'M12_FME_60_RAT']
        female_age_labels = ['ğŸ‘© 10-20ëŒ€', 'ğŸ‘© 30ëŒ€', 'ğŸ‘© 40ëŒ€', 'ğŸ‘© 50ëŒ€', 'ğŸ‘© 60ëŒ€+']
        female_colors = ['#E84393', '#D63031', '#FD79A8', '#FDCB6E', '#00B894']

        for col, label, color in zip(female_age_cols, female_age_labels, female_colors):
            if col in merchant_data.columns:
                data = merchant_data[col].fillna(0)
                ax3.plot(merchant_data['TA_YM'], data,
                        marker='s', linewidth=2, label=label, color=color, alpha=0.8)

        ax3.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
        ax3.set_ylabel('ì—¬ì„± ê³ ê° ë¹„ì¤‘ (%)', fontsize=11, fontweight='bold')
        ax3.set_title('ğŸ‘© ì—¬ì„± ê³ ê° - ì—°ë ¹ëŒ€ë³„ ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
        ax3.legend(fontsize=9, loc='best', ncol=2)
        ax3.grid(True, alpha=0.3, linestyle='--')
        ax3.tick_params(axis='x', rotation=45)
        ax3.set_ylim(0, max(100, merchant_data[female_age_cols].max().max() * 1.1) if any(col in merchant_data.columns for col in female_age_cols) else 100)

        # 4. ìœ„í—˜ì„± ì¶”ì´ (ìœ„í—˜ì ìˆ˜ + ê²½ë³´ë ˆë²¨)
        ax4 = axes[1, 0]

        # ìœ„í—˜ì ìˆ˜ ë¼ì¸
        ax4.plot(merchant_data['TA_YM'], merchant_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'],
                marker='o', linewidth=3, markersize=7, color='#E63946', label='ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜')
        ax4.fill_between(merchant_data['TA_YM'], merchant_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'],
                         alpha=0.2, color='#E63946')

        # ìœ„í—˜ êµ¬ê°„ í‘œì‹œ
        ax4.axhline(y=33, color='yellow', linestyle='--', linewidth=2, alpha=0.7, label='ì£¼ì˜')
        ax4.axhline(y=66, color='orange', linestyle='--', linewidth=2, alpha=0.7, label='ê²½ê³ ')

        ax4.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
        ax4.set_ylabel('ìœ„í—˜ì ìˆ˜', fontsize=11, fontweight='bold')
        ax4.set_title('ìœ„í—˜ì„± ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
        ax4.legend(fontsize=10, loc='best')
        ax4.grid(True, alpha=0.3, linestyle='--')
        ax4.tick_params(axis='x', rotation=45)
        ax4.set_ylim(0, 100)

        # 5. ì„±ë³„ ê³ ê° ë¹„ì¤‘ ë¹„êµ
        ax5 = axes[1, 1]

        # ìµœê·¼ 3ê°œì›” í‰ê·  ê³„ì‚°
        recent_3m = merchant_data.tail(3)
        male_total = recent_3m[male_age_cols].sum(axis=1).mean() if any(col in recent_3m.columns for col in male_age_cols) else 0
        female_total = recent_3m[female_age_cols].sum(axis=1).mean() if any(col in recent_3m.columns for col in female_age_cols) else 0

        gender_data = [male_total, female_total]
        gender_labels = ['ğŸ‘¨ ë‚¨ì„±', 'ğŸ‘© ì—¬ì„±']
        gender_colors = ['#3498db', '#e74c3c']

        bars = ax5.bar(gender_labels, gender_data, color=gender_colors, alpha=0.7, edgecolor='black', linewidth=2)

        # ê°’ í‘œì‹œ
        for bar in bars:
            height = bar.get_height()
            ax5.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.1f}%',
                    ha='center', va='bottom', fontsize=12, fontweight='bold')

        ax5.set_ylabel('ê³ ê° ë¹„ì¤‘ (%)', fontsize=11, fontweight='bold')
        ax5.set_title('ì„±ë³„ ê³ ê° ë¹„ì¤‘ ë¹„êµ (ìµœê·¼ 3ê°œì›” í‰ê· )', fontsize=13, fontweight='bold', pad=10)
        ax5.grid(True, alpha=0.3, linestyle='--', axis='y')
        ax5.set_ylim(0, max(gender_data) * 1.2 if max(gender_data) > 0 else 100)

        # 6. í˜„ì¬ ìƒíƒœ ìš”ì•½
        ax6 = axes[1, 2]
        ax6.axis('off')

        pred_level = int(latest['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'])
        pred_info = self.WARNING_LEVELS[pred_level]

        # ì£¼ë ¥ ì„¸ëŒ€ ì •ë³´
        main_gen = latest.get('ì£¼ë ¥ì„¸ëŒ€', 'N/A')
        if pd.isna(main_gen):
            main_gen = 'ì •ë³´ì—†ìŒ'

        summary = f"""
        ã€ í˜„ì¬ ê²½ë³´ ìƒíƒœ ã€‘

        {pred_info['emoji']} ì˜ˆì¸¡ ë ˆë²¨: {pred_info['name']}
        ğŸ“Š ìœ„í—˜ì ìˆ˜: {latest['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜']:.1f}ì 

        ã€ ìµœê·¼ ì§€í‘œ (3ê°œì›” í‰ê· ) ã€‘

        ğŸ“ˆ ë§¤ì¶œ ë³€í™”ìœ¨: {latest.get('RC_M1_SAA_num_ì¶”ì„¸3M', 0):.1f}%
        ğŸ‘¥ ê³ ê° ë³€í™”ìœ¨: {latest.get('RC_M1_UE_CUS_CN_num_ì¶”ì„¸3M', 0):.1f}%
        ğŸ”„ ì—°ì† í•˜ë½: {latest.get('RC_M1_SAA_num_ì—°ì†í•˜ë½', 0):.0f}ê°œì›”

        ã€ ì„±ë³„ ê³ ê° ì •ë³´ ã€‘

        ğŸ‘¨ ë‚¨ì„± ê³ ê°: {male_total:.1f}%
        ğŸ‘© ì—¬ì„± ê³ ê°: {female_total:.1f}%
        ğŸ¯ ì£¼ë ¥ ì„¸ëŒ€: {main_gen}

        ã€ ìš´ì˜ ì •ë³´ ã€‘

        ğŸ“… ìš´ì˜ ê¸°ê°„: {latest.get('ìš´ì˜ê°œì›”ìˆ˜', 0):.0f}ê°œì›”
        ğŸ¢ ì—…ì¢…: {mct_type}
        ğŸ“ ì§€ì—­: {latest.get('MCT_SIGUNGU_NM', 'N/A')}

        ã€ AI ë¶„ì„ ã€‘
        """

        # LLM ë¶„ì„ ì‚¬ìš©
        if self.use_llm:
            llm_analysis = self.analyze_risk_with_llm(latest)
            summary += f"\n{llm_analysis}"
        else:
            # ê¸°ë³¸ ë¶„ì„
            if pred_level == 3:
                summary += "\nğŸ”´ ì¦‰ê° ëŒ€ì‘ í•„ìš”\n    - ê²½ì˜ ì „ëµ ì „ë©´ ì¬ê²€í† \n    - ì „ë¬¸ ì»¨ì„¤íŒ… í•„ìˆ˜"
            elif pred_level == 2:
                summary += "\nğŸŸ  ê°œì„  ë°©ì•ˆ ìˆ˜ë¦½\n    - íƒ€ê²Ÿ ì„¸ëŒ€ ë§ˆì¼€íŒ… ê°•í™”\n    - ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            elif pred_level == 1:
                summary += "\nğŸŸ¡ ì˜ˆë°©ì  ê´€ë¦¬\n    - í˜„ ìƒíƒœ ëª¨ë‹ˆí„°ë§\n    - ì„±ì¥ ê¸°íšŒ íƒìƒ‰"
            else:
                summary += "\nğŸŸ¢ ì•ˆì •ì  ìš´ì˜\n    - í˜„ì¬ ì „ëµ ìœ ì§€\n    - ì¶”ê°€ ì„±ì¥ ë„ëª¨"

        ax6.text(0.05, 0.95, summary, transform=ax6.transAxes,
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor=pred_info['color'], alpha=0.15),
                family='malgun gothic')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def visualize_gender_generation_analysis(self, save_path='gender_generation_analysis.png'):
        """ì„±ë³„ êµ¬ë¶„ ì„¸ëŒ€ë³„ ë¶„ì„ ì‹œê°í™”"""
        print("ğŸ“Š ì„±ë³„ êµ¬ë¶„ ì„¸ëŒ€ë³„ ë¶„ì„ ì‹œê°í™” ì¤‘...")

        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ì„±ë³„ êµ¬ë¶„ ì„¸ëŒ€ë³„ ë§¤ì¶œ ë³€í™” ë¶„ì„ (2023-01 ~ 2024-12)',
                     fontsize=18, fontweight='bold', y=0.995)

        # 1. ë‚¨ì„± ì„¸ëŒ€ë³„ ì›”ë³„ ì¶”ì´
        ax1 = axes[0, 0]
        male_cols = ['M12_MAL_1020_RAT', 'M12_MAL_30_RAT', 'M12_MAL_40_RAT', 'M12_MAL_50_RAT', 'M12_MAL_60_RAT']

        if all(col in self.merged_data.columns for col in male_cols):
            monthly_male = self.merged_data.groupby('TA_YM')[male_cols].mean()

            ax1.plot(monthly_male.index, monthly_male['M12_MAL_1020_RAT'],
                    marker='o', linewidth=2, label='10-20ëŒ€', color='#4ECDC4')
            ax1.plot(monthly_male.index, monthly_male['M12_MAL_30_RAT'],
                    marker='s', linewidth=2, label='30ëŒ€', color='#6DD5DB')
            ax1.plot(monthly_male.index, monthly_male['M12_MAL_40_RAT'],
                    marker='^', linewidth=2, label='40ëŒ€', color='#8CDDE3')
            ax1.plot(monthly_male.index, monthly_male['M12_MAL_50_RAT'],
                    marker='D', linewidth=2, label='50ëŒ€', color='#ABE5EB')
            ax1.plot(monthly_male.index, monthly_male['M12_MAL_60_RAT'],
                    marker='v', linewidth=2, label='60ëŒ€+', color='#CAEDF3')

            ax1.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
            ax1.set_ylabel('í‰ê·  ë¹„ì¤‘ (%)', fontsize=11, fontweight='bold')
            ax1.set_title('ë‚¨ì„± ê³ ê° - ì—°ë ¹ëŒ€ë³„ ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
            ax1.legend(fontsize=9, loc='best', ncol=2)
            ax1.grid(True, alpha=0.3, linestyle='--')
            ax1.tick_params(axis='x', rotation=45)

        # 2. ì—¬ì„± ì„¸ëŒ€ë³„ ì›”ë³„ ì¶”ì´
        ax2 = axes[0, 1]
        female_cols = ['M12_FME_1020_RAT', 'M12_FME_30_RAT', 'M12_FME_40_RAT', 'M12_FME_50_RAT', 'M12_FME_60_RAT']

        if all(col in self.merged_data.columns for col in female_cols):
            monthly_female = self.merged_data.groupby('TA_YM')[female_cols].mean()

            ax2.plot(monthly_female.index, monthly_female['M12_FME_1020_RAT'],
                    marker='o', linewidth=2, label='10-20ëŒ€', color='#FF6B6B')
            ax2.plot(monthly_female.index, monthly_female['M12_FME_30_RAT'],
                    marker='s', linewidth=2, label='30ëŒ€', color='#FF8787')
            ax2.plot(monthly_female.index, monthly_female['M12_FME_40_RAT'],
                    marker='^', linewidth=2, label='40ëŒ€', color='#FFA5A5')
            ax2.plot(monthly_female.index, monthly_female['M12_FME_50_RAT'],
                    marker='D', linewidth=2, label='50ëŒ€', color='#FFC3C3')
            ax2.plot(monthly_female.index, monthly_female['M12_FME_60_RAT'],
                    marker='v', linewidth=2, label='60ëŒ€+', color='#FFE1E1')

            ax2.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
            ax2.set_ylabel('í‰ê·  ë¹„ì¤‘ (%)', fontsize=11, fontweight='bold')
            ax2.set_title('ì—¬ì„± ê³ ê° - ì—°ë ¹ëŒ€ë³„ ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
            ax2.legend(fontsize=9, loc='best', ncol=2)
            ax2.grid(True, alpha=0.3, linestyle='--')
            ax2.tick_params(axis='x', rotation=45)

        # 3. ì„±ë³„ ë¹„êµ (ìµœì‹  ì›”)
        ax3 = axes[0, 2]
        latest_data = self.merged_data[self.merged_data['TA_YM'] == self.merged_data['TA_YM'].max()]

        if 'ë‚¨ì„±ê³ ê°_ë¹„ì¤‘' in latest_data.columns and 'ì—¬ì„±ê³ ê°_ë¹„ì¤‘' in latest_data.columns:
            male_avg = latest_data['ë‚¨ì„±ê³ ê°_ë¹„ì¤‘'].mean()
            female_avg = latest_data['ì—¬ì„±ê³ ê°_ë¹„ì¤‘'].mean()

            bars = ax3.bar(['ë‚¨ì„±', 'ì—¬ì„±'], [male_avg, female_avg],
                          color=['#4ECDC4', '#FF6B6B'], alpha=0.7, edgecolor='black', linewidth=2)
            ax3.set_ylabel('í‰ê·  ë¹„ì¤‘ (%)', fontsize=11, fontweight='bold')
            ax3.set_title('ì„±ë³„ ê³ ê° ë¹„ì¤‘ ë¹„êµ', fontsize=13, fontweight='bold', pad=10)
            ax3.grid(axis='y', alpha=0.3, linestyle='--')

            for bar in bars:
                height = bar.get_height()
                ax3.text(bar.get_x() + bar.get_width()/2., height,
                        f'{height:.1f}%',
                        ha='center', va='bottom', fontsize=12, fontweight='bold')

        # 4. ë‚¨ì„± ì—°ë ¹ëŒ€ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜
        ax4 = axes[1, 0]
        if all(col in latest_data.columns for col in male_cols):
            # ì£¼ë ¥ ë‚¨ì„± ì—°ë ¹ëŒ€ ê³„ì‚°
            latest_data_copy = latest_data.copy()

            def get_main_male_age(row):
                ages = {
                    '10-20ëŒ€': row.get('M12_MAL_1020_RAT', 0),
                    '30ëŒ€': row.get('M12_MAL_30_RAT', 0),
                    '40ëŒ€': row.get('M12_MAL_40_RAT', 0),
                    '50ëŒ€': row.get('M12_MAL_50_RAT', 0),
                    '60ëŒ€+': row.get('M12_MAL_60_RAT', 0)
                }
                if all(pd.isna(v) or v == 0 for v in ages.values()):
                    return None
                return max(ages, key=ages.get)

            latest_data_copy['ì£¼ë ¥_ë‚¨ì„±ì—°ë ¹'] = latest_data_copy.apply(get_main_male_age, axis=1)
            latest_data_copy['ì£¼ë ¥_ë‚¨ì„±ì—°ë ¹'] = latest_data_copy['ì£¼ë ¥_ë‚¨ì„±ì—°ë ¹'].fillna('ì •ë³´ì—†ìŒ')

            male_risk = latest_data_copy.groupby('ì£¼ë ¥_ë‚¨ì„±ì—°ë ¹')['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].mean() # .sort_values(ascending=False)

            bars = ax4.barh(range(len(male_risk)), male_risk.values,
                           color='#4ECDC4', alpha=0.7, edgecolor='black')
            ax4.set_yticks(range(len(male_risk)))
            ax4.set_yticklabels(male_risk.index, fontsize=10)
            ax4.set_xlabel('í‰ê·  ìœ„í—˜ì ìˆ˜', fontsize=11, fontweight='bold')
            ax4.set_title('ë‚¨ì„± ì—°ë ¹ëŒ€ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜', fontsize=13, fontweight='bold', pad=10)
            ax4.grid(axis='x', alpha=0.3, linestyle='--')
            ax4.axvline(x=33, color='yellow', linestyle='--', linewidth=1.5, alpha=0.7)
            ax4.axvline(x=66, color='orange', linestyle='--', linewidth=1.5, alpha=0.7)

            for i, bar in enumerate(bars):
                width = bar.get_width()
                ax4.text(width + 1, bar.get_y() + bar.get_height()/2.,
                        f'{width:.1f}',
                        ha='left', va='center', fontsize=9, fontweight='bold')

        # 5. ì—¬ì„± ì—°ë ¹ëŒ€ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜
        ax5 = axes[1, 1]
        if all(col in latest_data.columns for col in female_cols):
            latest_data_copy = latest_data.copy()

            def get_main_female_age(row):
                ages = {
                    '10-20ëŒ€': row.get('M12_FME_1020_RAT', 0),
                    '30ëŒ€': row.get('M12_FME_30_RAT', 0),
                    '40ëŒ€': row.get('M12_FME_40_RAT', 0),
                    '50ëŒ€': row.get('M12_FME_50_RAT', 0),
                    '60ëŒ€+': row.get('M12_FME_60_RAT', 0)
                }
                if all(pd.isna(v) or v == 0 for v in ages.values()):
                    return None
                return max(ages, key=ages.get)

            latest_data_copy['ì£¼ë ¥_ì—¬ì„±ì—°ë ¹'] = latest_data_copy.apply(get_main_female_age, axis=1)
            latest_data_copy['ì£¼ë ¥_ì—¬ì„±ì—°ë ¹'] = latest_data_copy['ì£¼ë ¥_ì—¬ì„±ì—°ë ¹'].fillna('ì •ë³´ì—†ìŒ')

            female_risk = latest_data_copy.groupby('ì£¼ë ¥_ì—¬ì„±ì—°ë ¹')['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].mean() # .sort_values(ascending=False)

            bars = ax5.barh(range(len(female_risk)), female_risk.values,
                           color='#FF6B6B', alpha=0.7, edgecolor='black')
            ax5.set_yticks(range(len(female_risk)))
            ax5.set_yticklabels(female_risk.index, fontsize=10)
            ax5.set_xlabel('í‰ê·  ìœ„í—˜ì ìˆ˜', fontsize=11, fontweight='bold')
            ax5.set_title('ì—¬ì„± ì—°ë ¹ëŒ€ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜', fontsize=13, fontweight='bold', pad=10)
            ax5.grid(axis='x', alpha=0.3, linestyle='--')
            ax5.axvline(x=33, color='yellow', linestyle='--', linewidth=1.5, alpha=0.7)
            ax5.axvline(x=66, color='orange', linestyle='--', linewidth=1.5, alpha=0.7)

            for i, bar in enumerate(bars):
                width = bar.get_width()
                ax5.text(width + 1, bar.get_y() + bar.get_height()/2.,
                        f'{width:.1f}',
                        ha='left', va='center', fontsize=9, fontweight='bold')

        # 6. ì„±ë³„Ã—ì„¸ëŒ€ ì¡°í•© íˆíŠ¸ë§µ
        ax6 = axes[1, 2]
        if all(col in self.merged_data.columns for col in male_cols + female_cols):
            # í‰ê·  ê³„ì‚°
            heatmap_data = []
            ages = ['10-20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€', '60ëŒ€+']

            male_avgs = [
                latest_data['M12_MAL_1020_RAT'].mean(),
                latest_data['M12_MAL_30_RAT'].mean(),
                latest_data['M12_MAL_40_RAT'].mean(),
                latest_data['M12_MAL_50_RAT'].mean(),
                latest_data['M12_MAL_60_RAT'].mean()
            ]

            female_avgs = [
                latest_data['M12_FME_1020_RAT'].mean(),
                latest_data['M12_FME_30_RAT'].mean(),
                latest_data['M12_FME_40_RAT'].mean(),
                latest_data['M12_FME_50_RAT'].mean(),
                latest_data['M12_FME_60_RAT'].mean()
            ]

            heatmap_df = pd.DataFrame({
                'ë‚¨ì„±': male_avgs,
                'ì—¬ì„±': female_avgs
            }, index=ages)

            im = ax6.imshow(heatmap_df.T, cmap='YlOrRd', aspect='auto')

            ax6.set_xticks(range(len(ages)))
            ax6.set_xticklabels(ages, fontsize=10)
            ax6.set_yticks([0, 1])
            ax6.set_yticklabels(['ë‚¨ì„±', 'ì—¬ì„±'], fontsize=11)
            ax6.set_title('ì„±ë³„Ã—ì—°ë ¹ëŒ€ ê³ ê° ë¹„ì¤‘ íˆíŠ¸ë§µ', fontsize=13, fontweight='bold', pad=10)

            # ê°’ í‘œì‹œ
            for i in range(2):
                for j in range(len(ages)):
                    text = ax6.text(j, i, f'{heatmap_df.iloc[j, i]:.1f}',
                                   ha="center", va="center", color="black", fontsize=10, fontweight='bold')

            plt.colorbar(im, ax=ax6, label='í‰ê·  ë¹„ì¤‘ (%)')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def visualize_time_period_analysis(self, save_path='time_period_analysis.png'):
        """ì‹œê°„ ê¸°ê°„ë³„ ë¶„ì„ ì‹œê°í™” (2023-01 ~ 2024-12)"""
        print("ğŸ“Š ê¸°ê°„ë³„ ë¶„ì„ ì‹œê°í™” ì¤‘...")

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ê¸°ê°„ë³„ ê²½ì˜ ì§€í‘œ ë¶„ì„ (2023-01 ~ 2024-12)',
                     fontsize=18, fontweight='bold', y=0.995)

        # ì›”ë³„ ì§‘ê³„
        monthly_agg = self.merged_data.groupby('TA_YM').agg({
            'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜': 'mean',
            'RC_M1_SAA_num': 'mean',
            'RC_M1_TO_UE_CT_num': 'mean',
            'ENCODED_MCT': 'nunique'
        }).reset_index()

        # 1. ì›”ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜ ì¶”ì´
        ax1 = axes[0, 0]
        ax1.plot(monthly_agg['TA_YM'], monthly_agg['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'],
                marker='o', linewidth=3, markersize=6, color='#E63946', label='í‰ê·  ìœ„í—˜ì ìˆ˜')
        ax1.fill_between(monthly_agg['TA_YM'], monthly_agg['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'],
                         alpha=0.3, color='#E63946')

        # ìœ„í—˜ êµ¬ê°„ í‘œì‹œ
        ax1.axhline(y=33, color='yellow', linestyle='--', linewidth=2, alpha=0.7, label='ì£¼ì˜')
        ax1.axhline(y=66, color='orange', linestyle='--', linewidth=2, alpha=0.7, label='ê²½ê³ ')

        ax1.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
        ax1.set_ylabel('í‰ê·  ìœ„í—˜ì ìˆ˜', fontsize=11, fontweight='bold')
        ax1.set_title('ì›”ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜ ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
        ax1.legend(fontsize=10, loc='best')
        ax1.grid(True, alpha=0.3, linestyle='--')
        ax1.tick_params(axis='x', rotation=45)

        # 2. ì›”ë³„ ê²½ë³´ ë ˆë²¨ ë¶„í¬
        ax2 = axes[0, 1]
        monthly_warnings = self.merged_data.groupby(['TA_YM', 'ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨']).size().unstack(fill_value=0)

        colors = ['green', 'yellow', 'orange', 'red']
        for level in range(4):
            if level in monthly_warnings.columns:
                ax2.plot(monthly_warnings.index, monthly_warnings[level],
                        marker='o', linewidth=2.5, markersize=5,
                        label=f"{self.WARNING_LEVELS[level]['emoji']} {self.WARNING_LEVELS[level]['name']}",
                        color=colors[level])

        ax2.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
        ax2.set_ylabel('ê°€ë§¹ì  ìˆ˜', fontsize=11, fontweight='bold')
        ax2.set_title('ì›”ë³„ ê²½ë³´ ë ˆë²¨ë³„ ê°€ë§¹ì  ìˆ˜', fontsize=13, fontweight='bold', pad=10)
        ax2.legend(fontsize=9, loc='best', framealpha=0.9)
        ax2.grid(True, alpha=0.3, linestyle='--')
        ax2.tick_params(axis='x', rotation=45)

        # 3. ì—°ë„ë³„/ë¶„ê¸°ë³„ ë¹„êµ
        ax3 = axes[1, 0]
        self.merged_data['ì—°ë„_ë¶„ê¸°'] = (
            self.merged_data['ì—°ë„'].astype(str) + '-Q' +
            self.merged_data['ë¶„ê¸°'].astype(str)
        )

        quarter_risk = self.merged_data.groupby('ì—°ë„_ë¶„ê¸°')['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].mean().sort_index()

        bars = ax3.bar(range(len(quarter_risk)), quarter_risk.values,
                      color='steelblue', alpha=0.7, edgecolor='black', linewidth=1.5)
        ax3.set_xticks(range(len(quarter_risk)))
        ax3.set_xticklabels(quarter_risk.index, fontsize=10, rotation=45)
        ax3.set_ylabel('í‰ê·  ìœ„í—˜ì ìˆ˜', fontsize=11, fontweight='bold')
        ax3.set_title('ë¶„ê¸°ë³„ í‰ê·  ìœ„í—˜ì ìˆ˜', fontsize=13, fontweight='bold', pad=10)
        ax3.grid(axis='y', alpha=0.3, linestyle='--')

        # ìƒ‰ìƒ êµ¬ë¶„
        for i, bar in enumerate(bars):
            height = bar.get_height()
            if height >= 66:
                bar.set_color('red')
            elif height >= 33:
                bar.set_color('orange')
            else:
                bar.set_color('green')
            bar.set_alpha(0.7)

            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.1f}',
                    ha='center', va='bottom', fontsize=9, fontweight='bold')

        # 4. í™œë™ ê°€ë§¹ì  ìˆ˜ ì¶”ì´
        ax4 = axes[1, 1]
        ax4.plot(monthly_agg['TA_YM'], monthly_agg['ENCODED_MCT'],
                marker='o', linewidth=3, markersize=6, color='#457B9D', label='í™œë™ ê°€ë§¹ì  ìˆ˜')
        ax4.fill_between(monthly_agg['TA_YM'], monthly_agg['ENCODED_MCT'],
                         alpha=0.3, color='#457B9D')

        ax4.set_xlabel('ê¸°ê°„', fontsize=11, fontweight='bold')
        ax4.set_ylabel('ê°€ë§¹ì  ìˆ˜', fontsize=11, fontweight='bold')
        ax4.set_title('ì›”ë³„ í™œë™ ê°€ë§¹ì  ìˆ˜', fontsize=13, fontweight='bold', pad=10)
        ax4.legend(fontsize=10)
        ax4.grid(True, alpha=0.3, linestyle='--')
        ax4.tick_params(axis='x', rotation=45)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def visualize_confusion_matrix(self, y_test, y_pred, save_path='ml_confusion_matrix.png'):
        """í˜¼ë™ í–‰ë ¬"""
        print("ğŸ“Š í˜¼ë™ í–‰ë ¬ ì‹œê°í™” ì¤‘...")

        y_pred_class = np.argmax(y_pred, axis=1)
        cm = confusion_matrix(y_test, y_pred_class)

        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                    xticklabels=[f"{self.WARNING_LEVELS[i]['emoji']} {self.WARNING_LEVELS[i]['name']}"
                                for i in range(4)],
                    yticklabels=[f"{self.WARNING_LEVELS[i]['emoji']} {self.WARNING_LEVELS[i]['name']}"
                                for i in range(4)],
                    cbar_kws={'label': 'ê±´ìˆ˜'})

        ax.set_xlabel('ì˜ˆì¸¡ ê²½ë³´ ë ˆë²¨', fontsize=13, fontweight='bold')
        ax.set_ylabel('ì‹¤ì œ ê²½ë³´ ë ˆë²¨', fontsize=13, fontweight='bold')
        ax.set_title('í˜¼ë™ í–‰ë ¬ (Confusion Matrix)', fontsize=16, fontweight='bold', pad=15)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def generate_report(self, output_file='ml_warning_report.csv'):
        """ê²½ë³´ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ“ ê²½ë³´ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

        latest_month = self.merged_data['TA_YM'].max()
        latest_data = self.merged_data[self.merged_data['TA_YM'] == latest_month].copy()

        report_cols = [
            'ENCODED_MCT', 'MCT_NM', 'HPSN_MCT_BZN_CD_NM', 'MCT_SIGUNGU_NM',
            'ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨', 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜',
            'ì˜ˆì¸¡_í™•ë¥ _0', 'ì˜ˆì¸¡_í™•ë¥ _1', 'ì˜ˆì¸¡_í™•ë¥ _2', 'ì˜ˆì¸¡_í™•ë¥ _3',
            'RC_M1_SAA_num', 'RC_M1_SAA_num_ë³€í™”ìœ¨_3M', 'RC_M1_SAA_num_ì—°ì†í•˜ë½',
            'ì£¼ë ¥ì„¸ëŒ€', '2030ì„¸ëŒ€_ë¹„ì¤‘', '4050ì„¸ëŒ€_ë¹„ì¤‘', '60ëŒ€ì´ìƒ_ë¹„ì¤‘',
            'ìš´ì˜ê°œì›”ìˆ˜', 'ê°œì—…ê²½ê³¼ì¼'
        ]

        report_cols = [col for col in report_cols if col in latest_data.columns]
        report = latest_data[report_cols].copy()

        # ê²½ë³´ëª… ì¶”ê°€
        report['ê²½ë³´ëª…'] = report['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'].map(
            lambda x: self.WARNING_LEVELS[int(x)]['name']
        )

        report = report.sort_values('ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜', ascending=False)

        # LLM ë¶„ì„ ì¶”ê°€ (ê³ ìœ„í—˜ ê°€ë§¹ì  ìƒìœ„ 20ê°œë§Œ)
        if self.use_llm:
            print("ğŸ¤– LLM ë¶„ì„ ì§„í–‰ ì¤‘ (ê³ ìœ„í—˜ ìƒìœ„ 20ê°œ)...")
            llm_analyses = []

            for idx, row in report.head(20).iterrows():
                analysis = self.analyze_risk_with_llm(row)
                llm_analyses.append(analysis)
                print(f"  âœ“ {row.get('MCT_NM', 'N/A')} ë¶„ì„ ì™„ë£Œ")

            # ìƒìœ„ 20ê°œì—ë§Œ LLM ë¶„ì„ ê²°ê³¼ ì¶”ê°€
            report.loc[report.head(20).index, 'AI_ë¶„ì„'] = llm_analyses

        report.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ“ ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")
        print(f"  ì´ {len(report):,}ê°œ ê°€ë§¹ì \n")

        return report

    def analyze_risk_with_llm(self, merchant_data_row, shap_values=None):
        """LLMì„ ì‚¬ìš©í•œ ìœ„í—˜ ì˜ˆì¸¡ ë¶„ì„"""
        if not self.use_llm or self.openai_client is None:
            return self._default_risk_analysis(merchant_data_row)

        try:
            # ê°€ë§¹ì  ë°ì´í„° ìš”ì•½
            pred_level = int(merchant_data_row['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'])
            risk_score = merchant_data_row['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜']

            # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""ë‹¹ì‹ ì€ ê°€ë§¹ì  ê²½ì˜ ìœ„ê¸° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°€ë§¹ì ì˜ ìœ„í—˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì„¤ëª…í•´ì£¼ì„¸ìš”.

ã€ ê°€ë§¹ì  ì •ë³´ ã€‘
- ê°€ë§¹ì ëª…: {merchant_data_row.get('MCT_NM', 'N/A')}
- ì—…ì¢…: {merchant_data_row.get('HPSN_MCT_BZN_CD_NM', 'N/A')}
- ì§€ì—­: {merchant_data_row.get('MCT_SIGUNGU_NM', 'N/A')}
- ìš´ì˜ ê¸°ê°„: {merchant_data_row.get('ìš´ì˜ê°œì›”ìˆ˜', 0):.0f}ê°œì›”

ã€ ì˜ˆì¸¡ ê²°ê³¼ ã€‘
- ì˜ˆì¸¡ ê²½ë³´ ë ˆë²¨: {self.WARNING_LEVELS[pred_level]['name']} ({self.WARNING_LEVELS[pred_level]['emoji']})
- ìœ„í—˜ ì ìˆ˜: {risk_score:.1f}/100ì 
- ì•ˆì „ í™•ë¥ : {merchant_data_row.get('ì˜ˆì¸¡_í™•ë¥ _0', 0)*100:.1f}%
- ì£¼ì˜ í™•ë¥ : {merchant_data_row.get('ì˜ˆì¸¡_í™•ë¥ _1', 0)*100:.1f}%
- ê²½ê³  í™•ë¥ : {merchant_data_row.get('ì˜ˆì¸¡_í™•ë¥ _2', 0)*100:.1f}%
- ìœ„í—˜ í™•ë¥ : {merchant_data_row.get('ì˜ˆì¸¡_í™•ë¥ _3', 0)*100:.1f}%

ã€ ì£¼ìš” ì§€í‘œ ã€‘
- ë§¤ì¶œ ìˆ˜ì¤€ (ë°±ë¶„ìœ„): {merchant_data_row.get('RC_M1_SAA_num', 0):.1f}
- 3ê°œì›” ë§¤ì¶œ ë³€í™”ìœ¨: {merchant_data_row.get('RC_M1_SAA_num_ë³€í™”ìœ¨_3M', 0):.1f}%
- ì—°ì† í•˜ë½ ê°œì›”: {merchant_data_row.get('RC_M1_SAA_num_ì—°ì†í•˜ë½', 0):.0f}ê°œì›”
- ê³ ê° ìˆ˜ ë³€í™”ìœ¨: {merchant_data_row.get('RC_M1_UE_CUS_CN_num_ë³€í™”ìœ¨_3M', 0):.1f}%

ã€ ì„¸ëŒ€ë³„ ì •ë³´ ã€‘
- ì£¼ë ¥ ì„¸ëŒ€: {merchant_data_row.get('ì£¼ë ¥ì„¸ëŒ€', 'ì •ë³´ì—†ìŒ')}
- 2030ì„¸ëŒ€ ë¹„ì¤‘: {merchant_data_row.get('2030ì„¸ëŒ€_ë¹„ì¤‘', 0):.1f}%
- 4050ì„¸ëŒ€ ë¹„ì¤‘: {merchant_data_row.get('4050ì„¸ëŒ€_ë¹„ì¤‘', 0):.1f}%
- 60ëŒ€ ì´ìƒ ë¹„ì¤‘: {merchant_data_row.get('60ëŒ€ì´ìƒ_ë¹„ì¤‘', 0):.1f}%

ã€ ìš”ì²­ì‚¬í•­ ã€‘
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš” (ìµœëŒ€ 150ì):

1. ìœ„í—˜ ìš”ì¸ (1-2ê°€ì§€ í•µì‹¬ ìš”ì¸)
2. êµ¬ì²´ì  ê¶Œì¥ ì¡°ì¹˜ (ì‹¤í–‰ ê°€ëŠ¥í•œ 1-2ê°€ì§€)

**ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.**"""

            response = self.openai_client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê°€ë§¹ì  ê²½ì˜ ìœ„ê¸° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=300
            )

            content = response.choices[0].message.content
            return content.strip() if content else self._default_risk_analysis(merchant_data_row)

        except Exception as e:
            print(f"âš ï¸  LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._default_risk_analysis(merchant_data_row)

    def analyze_situation_with_llm(self, merchant_data_row):
        """LLMì„ ì‚¬ìš©í•œ ìƒí™© ë¶„ì„"""
        if not self.use_llm or self.openai_client is None:
            return self._default_situation_analysis(merchant_data_row)

        try:
            pred_level = int(merchant_data_row['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'])

            prompt = f"""ë‹¹ì‹ ì€ ê°€ë§¹ì  ê²½ì˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°€ë§¹ì ì˜ í˜„ì¬ ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

ã€ ê¸°ë³¸ ì •ë³´ ã€‘
- ì—…ì¢…: {merchant_data_row.get('HPSN_MCT_BZN_CD_NM', 'N/A')}
- ì§€ì—­: {merchant_data_row.get('MCT_SIGUNGU_NM', 'N/A')}
- ìš´ì˜ ê¸°ê°„: {merchant_data_row.get('ìš´ì˜ê°œì›”ìˆ˜', 0):.0f}ê°œì›”

ã€ ê²½ì˜ ì§€í‘œ ã€‘
- í˜„ì¬ ê²½ë³´: {self.WARNING_LEVELS[pred_level]['name']}
- ë§¤ì¶œ ì¶”ì„¸: {merchant_data_row.get('RC_M1_SAA_num_ì¶”ì„¸3M', 0):.1f}%
- ë§¤ì¶œ ë³€ë™ì„±: {merchant_data_row.get('RC_M1_SAA_num_STD3M', 0):.1f}
- ê³ ê° ìˆ˜ ì¶”ì„¸: {merchant_data_row.get('RC_M1_UE_CUS_CN_num_ì¶”ì„¸3M', 0):.1f}%

ã€ ê³ ê° êµ¬ì¡° ã€‘
- ì£¼ë ¥ ì„¸ëŒ€: {merchant_data_row.get('ì£¼ë ¥ì„¸ëŒ€', 'ì •ë³´ì—†ìŒ')}
- 2030ì„¸ëŒ€ ë³€í™”: {merchant_data_row.get('2030ì„¸ëŒ€_ë¹„ì¤‘_ë³€í™”_3M', 0):.1f}%p
- 4050ì„¸ëŒ€ ë³€í™”: {merchant_data_row.get('4050ì„¸ëŒ€_ë¹„ì¤‘_ë³€í™”_3M', 0):.1f}%p
- ê³ ê° ë‹¤ì–‘ì„±: {merchant_data_row.get('ê³ ê°ë‹¤ì–‘ì„±ì§€ìˆ˜', 0):.2f}

ã€ ìš”ì²­ì‚¬í•­ ã€‘
ë‹¤ìŒì„ í¬í•¨í•˜ì—¬ 200ì ì´ë‚´ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ìƒí™© ì§„ë‹¨ (í•µì‹¬ ì´ìŠˆ 1-2ê°œ)
2. ê·¼ë³¸ ì›ì¸ ì¶”ì •
3. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ 1ê°€ì§€"""

            response = self.openai_client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ ê²½ì˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=400
            )

            content = response.choices[0].message.content
            return content.strip() if content else self._default_situation_analysis(merchant_data_row)

        except Exception as e:
            print(f"âš ï¸  LLM ìƒí™© ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._default_situation_analysis(merchant_data_row)

    def _default_risk_analysis(self, merchant_data_row):
        """ê¸°ë³¸ ìœ„í—˜ ë¶„ì„ (LLM ì—†ì´)"""
        pred_level = int(merchant_data_row['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'])

        if pred_level == 3:
            return "ìœ„í—˜ ìš”ì¸: ë§¤ì¶œ ê¸‰ë½ ë° ì—°ì† í•˜ë½\nê¶Œì¥ ì¡°ì¹˜: ì¦‰ê° ê²½ì˜ ì „ëµ ì¬ê²€í† , ì „ë¬¸ ì»¨ì„¤íŒ… í•„ìˆ˜"
        elif pred_level == 2:
            return "ìœ„í—˜ ìš”ì¸: ë§¤ì¶œ í•˜ë½ ë° ê³ ê° ê°ì†Œ\nê¶Œì¥ ì¡°ì¹˜: íƒ€ê²Ÿ ë§ˆì¼€íŒ… ê°•í™”, ë¹„ìš© êµ¬ì¡° ìµœì í™”"
        elif pred_level == 1:
            return "í˜„ì¬ ìƒíƒœ: ì•ˆì •ì ì´ë‚˜ ëª¨ë‹ˆí„°ë§ í•„ìš”\nê¶Œì¥ ì¡°ì¹˜: ì˜ˆë°©ì  ê´€ë¦¬, ì„±ì¥ ê¸°íšŒ íƒìƒ‰"
        else:
            return "í˜„ì¬ ìƒíƒœ: ì•ˆì •ì  ìš´ì˜\nê¶Œì¥ ì¡°ì¹˜: í˜„ì¬ ì „ëµ ìœ ì§€, ì¶”ê°€ ì„±ì¥ ë„ëª¨"

    def _default_situation_analysis(self, merchant_data_row):
        """ê¸°ë³¸ ìƒí™© ë¶„ì„ (LLM ì—†ì´)"""
        pred_level = int(merchant_data_row['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'])
        sales_change = merchant_data_row.get('RC_M1_SAA_num_ë³€í™”ìœ¨_3M', 0)
        main_gen = merchant_data_row.get('ì£¼ë ¥ì„¸ëŒ€', 'ì •ë³´ì—†ìŒ')

        if pred_level >= 2:
            return f"ìƒí™©: {sales_change:.1f}% ë§¤ì¶œ í•˜ë½ ì¤‘. ì£¼ë ¥ ì„¸ëŒ€({main_gen}) ì´íƒˆ ê°€ëŠ¥ì„±.\nê°œì„ ì•ˆ: ì„¸ëŒ€ë³„ ë§ì¶¤ ë§ˆì¼€íŒ… ë° ê³ ê° ì¬ìœ ì¹˜ ìº í˜ì¸ ì‹¤í–‰."
        else:
            return f"ìƒí™©: ì•ˆì •ì  ìš´ì˜ ì¤‘. ì£¼ë ¥ ì„¸ëŒ€: {main_gen}\nì œì•ˆ: í˜„ ê³ ê°ì¸µ ìœ ì§€ ë° ì‹ ê·œ ì„¸ëŒ€ í™•ë³´ ë³‘í–‰."

    def print_summary(self):
        """ìš”ì•½ í†µê³„"""
        print("=" * 80)
        print("ğŸ“Š ML ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ - ìš”ì•½")
        print("=" * 80)

        latest_month = self.merged_data['TA_YM'].max()
        latest_data = self.merged_data[self.merged_data['TA_YM'] == latest_month]

        print(f"\nğŸ“… ë¶„ì„ ê¸°ê°„: {self.merged_data['TA_YM'].min().strftime('%Yë…„ %mì›”')} ~ {latest_month.strftime('%Yë…„ %mì›”')}")
        print(f"ğŸ¢ ë¶„ì„ ê°€ë§¹ì  ìˆ˜: {len(latest_data):,}ê°œ\n")

        print("ã€ ì˜ˆì¸¡ ê²½ë³´ ë ˆë²¨ë³„ í˜„í™© ã€‘")
        for level in range(4):
            name = self.WARNING_LEVELS[level]['name']
            emoji = self.WARNING_LEVELS[level]['emoji']
            count = (latest_data['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'] == level).sum()
            pct = count / len(latest_data) * 100
            print(f"  {emoji} {name:4s}: {count:6,}ê°œ ({pct:5.1f}%)")

        print(f"\nã€ ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜ í†µê³„ ã€‘")
        print(f"  í‰ê· : {latest_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].mean():.1f}ì ")
        print(f"  ì¤‘ì•™ê°’: {latest_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].median():.1f}ì ")
        print(f"  ìµœëŒ€: {latest_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].max():.1f}ì ")

        print("\nã€ ê³ ìœ„í—˜ ê°€ë§¹ì  (Top 10) ã€‘")
        high_risk = latest_data.nlargest(10, 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜')[
            ['MCT_NM', 'HPSN_MCT_BZN_CD_NM', 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜', 'ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨']
        ]
        for idx, row in enumerate(high_risk.itertuples(), 1):
            level_name = self.WARNING_LEVELS[int(row.ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨)]['name']
            mct_name = str(row.MCT_NM)[:15] if pd.notna(row.MCT_NM) else 'N/A'
            bzn_name = str(row.HPSN_MCT_BZN_CD_NM)[:15] if pd.notna(row.HPSN_MCT_BZN_CD_NM) else 'N/A'
            print(f"  {idx:2d}. {mct_name:15s} | {bzn_name:15s} | {row.ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜:5.1f}ì  | {level_name}")

        # ì„¸ëŒ€ë³„ í†µê³„
        if 'ì£¼ë ¥ì„¸ëŒ€' in latest_data.columns:
            print("\nã€ ì£¼ë ¥ ì„¸ëŒ€ë³„ í˜„í™© ã€‘")
            # NaN ê°’ì„ 'ì •ë³´ì—†ìŒ'ìœ¼ë¡œ í‘œì‹œ
            latest_data_copy = latest_data.copy()
            latest_data_copy['ì£¼ë ¥ì„¸ëŒ€'] = latest_data_copy['ì£¼ë ¥ì„¸ëŒ€'].fillna('ì •ë³´ì—†ìŒ')

            gen_stats = latest_data_copy.groupby('ì£¼ë ¥ì„¸ëŒ€').agg({
                'ENCODED_MCT': 'count',
                'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜': 'mean'
            }).round(1)
            gen_stats.columns = ['ê°€ë§¹ì  ìˆ˜', 'í‰ê·  ìœ„í—˜ì ìˆ˜']
            for gen, row in gen_stats.iterrows():
                gen_display = str(gen) if gen != 'ì •ë³´ì—†ìŒ' else 'ì •ë³´ì—†ìŒ'
                print(f"  {gen_display:8s}: {int(row['ê°€ë§¹ì  ìˆ˜']):5,}ê°œ (í‰ê·  ìœ„í—˜ì ìˆ˜: {row['í‰ê·  ìœ„í—˜ì ìˆ˜']:5.1f}ì )")

        print("\n" + "=" * 80 + "\n")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("=" * 80)
    print("ğŸš€ ML ê¸°ë°˜ ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ")
    print("   (Pure LightGBM / ì „ì²´ ë°ì´í„°ì…‹ í™œìš© / ì„¸ëŒ€ë³„ ë¶„ì„ í¬í•¨)")
    print("=" * 80)
    print()

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™” (2023-01 ~ 2024-12)
    ews = MLEarlyWarningSystem(
        data_path='./data/',
        start_date='2023-01',
        end_date='2024-12'
    )

    # 1. ë°ì´í„° ë¡œë“œ
    ews.load_data()

    # 2. ë°ì´í„° í†µí•©
    ews.merge_all_data()

    # 3. ì¢…í•© íŠ¹ì„± ìƒì„±
    ews.create_comprehensive_features()

    # 4. íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
    ews.create_target_variable()

    # 5. ML íŠ¹ì„± ì¤€ë¹„
    ews.prepare_ml_features()

    # 6. ëª¨ë¸ í•™ìŠµ
    X_test, y_test, y_pred = ews.train_model()

    # 7. ìš”ì•½
    ews.print_summary()

    # 8. ì‹œê°í™”
    print("ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...\n")
    ews.visualize_feature_importance('ml_feature_importance.png', top_n=40)
    ews.visualize_confusion_matrix(y_test, y_pred, 'ml_confusion_matrix.png')
    ews.visualize_generation_analysis('generation_analysis.png')
    ews.visualize_gender_generation_analysis('gender_generation_analysis.png')
    ews.visualize_time_period_analysis('time_period_analysis.png')

    # 9. ë¦¬í¬íŠ¸
    report = ews.generate_report('ml_warning_report.csv')

    # 10. ê³ ìœ„í—˜ ê°€ë§¹ì  ìƒì„¸ ë¶„ì„
    print("ğŸ” ê³ ìœ„í—˜ ê°€ë§¹ì  ìƒì„¸ ë¶„ì„...\n")
    top_risk = report.nlargest(5, 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜')['ENCODED_MCT'].values

    for idx, mct_id in enumerate(top_risk, 1):
        ews.visualize_merchant_detail(mct_id, f'merchant_detail_top{idx}.png')

    print("=" * 80)
    print("âœ… ML ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ ì™„ë£Œ!")
    print("=" * 80)
    print("\nìƒì„±ëœ íŒŒì¼:")
    print("  ğŸ“Š ml_feature_importance.png - íŠ¹ì„± ì¤‘ìš”ë„ (ìƒ‰ìƒë³„ ê·¸ë£¹)")
    print("  ğŸ“Š ml_confusion_matrix.png - í˜¼ë™ í–‰ë ¬")
    print("  ğŸ“Š generation_analysis.png - ì„¸ëŒ€ë³„ ë¶„ì„ (í†µí•©)")
    print("  ğŸ“Š gender_generation_analysis.png - ì„±ë³„ êµ¬ë¶„ ì„¸ëŒ€ë³„ ë¶„ì„")
    print("  ğŸ“Š time_period_analysis.png - ê¸°ê°„ë³„ ë¶„ì„ (2023-2024)")
    print("  ğŸ” merchant_detail_top1~5.png - ê³ ìœ„í—˜ ê°€ë§¹ì  ìƒì„¸ ë¶„ì„")
    print("  ğŸ“ ml_warning_report.csv - ê²½ë³´ ë¦¬í¬íŠ¸")
    print()


if __name__ == "__main__":
    main()
