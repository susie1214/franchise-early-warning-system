# -*- coding: utf-8 -*-
"""
ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ (LightGBM ë²„ì „)
- 4ë‹¨ê³„ ê²½ë³´ ì‹œìŠ¤í…œ: ì•ˆì „(Green) -> ì£¼ì˜(Yellow) -> ê²½ê³ (Orange) -> ìœ„í—˜(Red)
- LightGBMì„ í™œìš©í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ìœ„í—˜ë„ ì˜ˆì¸¡
- ì‹œê³„ì—´ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê°•í™”
"""

import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import shap

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['gulim', 'Symbol']
plt.rcParams['axes.unicode_minus'] = False

class LGBMEarlyWarningSystem:
    """LightGBM ê¸°ë°˜ ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ"""

    def __init__(self, data_path='./data/'):
        """ì´ˆê¸°í™”"""
        self.data_path = data_path
        self.merchant_data = None
        self.sales_data = None
        self.customer_data = None
        self.rental_data = None
        self.flow_data = None
        self.merged_data = None
        self.model = None
        self.feature_cols = []
        self.label_encoders = {}

        # ê²½ë³´ ë ˆë²¨ ì •ì˜
        self.WARNING_LEVELS = {
            0: {'name': 'ì•ˆì „', 'color': 'green', 'emoji': 'ğŸŸ¢'},
            1: {'name': 'ì£¼ì˜', 'color': 'yellow', 'emoji': 'ğŸŸ¡'},
            2: {'name': 'ê²½ê³ ', 'color': 'orange', 'emoji': 'ğŸŸ '},
            3: {'name': 'ìœ„í—˜', 'color': 'red', 'emoji': 'ğŸ”´'}
        }

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("=" * 80)
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("=" * 80)

        self.merchant_data = pd.read_csv(f'{self.data_path}big_data_set1_f_v2.csv', encoding='utf-8-sig')
        print(f"âœ“ ê°€ë§¹ì  ì •ë³´: {len(self.merchant_data):,}ê°œ")

        self.sales_data = pd.read_csv(f'{self.data_path}big_data_set2_f_sorted.csv', encoding='utf-8-sig')
        self.sales_data['TA_YM'] = pd.to_datetime(self.sales_data['TA_YM'], format='%Y%m')
        print(f"âœ“ ë§¤ì¶œ ë°ì´í„°: {len(self.sales_data):,}ê±´")

        self.customer_data = pd.read_csv(f'{self.data_path}big_data_set3_f_sorted.csv', encoding='utf-8-sig')
        self.customer_data['TA_YM'] = pd.to_datetime(self.customer_data['TA_YM'], format='%Y%m')
        print(f"âœ“ ê³ ê° ë°ì´í„°: {len(self.customer_data):,}ê±´")

        self.rental_data = pd.read_csv(f'{self.data_path}rental_p.csv', encoding='utf-8-sig')
        print(f"âœ“ ì„ëŒ€ë£Œ ë°ì´í„°: {len(self.rental_data):,}ê±´")

        self.flow_data = pd.read_csv(f'{self.data_path}flow_f.csv', encoding='utf-8-sig')
        print(f"âœ“ ìœ ë™ì¸êµ¬ ë°ì´í„°: {len(self.flow_data):,}ê±´")
        print()

    def merge_all_data(self):
        """ëª¨ë“  ë°ì´í„° í†µí•©"""
        print("ğŸ”— ë°ì´í„° í†µí•© ì¤‘...")

        # ë§¤ì¶œ + ê³ ê° ë°ì´í„°
        self.merged_data = pd.merge(
            self.sales_data,
            self.customer_data,
            on=['ENCODED_MCT', 'TA_YM'],
            how='inner'
        )

        # ê°€ë§¹ì  ì •ë³´
        self.merged_data = pd.merge(
            self.merged_data,
            self.merchant_data,
            on='ENCODED_MCT',
            how='left'
        )

        # ì„ëŒ€ë£Œ ë°ì´í„° (ë¶„ê¸° -> ì›”ë¡œ í™•ì¥)
        self.rental_data['ê¸°ê°„'] = pd.to_datetime(self.rental_data['ê¸°ê°„(ë¶„ê¸°)'], format='%Y%m')
        rental_expanded = []
        for _, row in self.rental_data.iterrows():
            for i in range(3):  # ë¶„ê¸°ë‹¹ 3ê°œì›”
                new_row = row.copy()
                new_row['TA_YM'] = row['ê¸°ê°„'] + pd.DateOffset(months=i)
                rental_expanded.append(new_row)

        rental_df = pd.DataFrame(rental_expanded)
        self.merged_data = pd.merge(
            self.merged_data,
            rental_df[['TA_YM', 'í–‰ì •êµ¬ì—­', 'ì „ì²´(ë‹¨ìœ„:ì›/í‰)', '1ì¸µ(ë‹¨ìœ„:ì›/í‰)', '1ì¸µ ì™¸(ë‹¨ìœ„:ì›/í‰)']],
            left_on=['TA_YM', 'LEGAL_DONG'],
            right_on=['TA_YM', 'í–‰ì •êµ¬ì—­'],
            how='left'
        )

        # ìœ ë™ì¸êµ¬ ë°ì´í„° (ë¶„ê¸° -> ì›”ë¡œ í™•ì¥)
        self.flow_data['ê¸°ê°„'] = pd.to_datetime(self.flow_data['ê¸°ê°„(ë¶„ê¸°)'], format='%Y%m')
        flow_expanded = []
        for _, row in self.flow_data.iterrows():
            for i in range(3):
                new_row = row.copy()
                new_row['TA_YM'] = row['ê¸°ê°„'] + pd.DateOffset(months=i)
                flow_expanded.append(new_row)

        flow_df = pd.DataFrame(flow_expanded)
        self.merged_data = pd.merge(
            self.merged_data,
            flow_df[['TA_YM', 'í–‰ì êµ¬ì—­', 'ìœ ë™ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)', 'ì£¼ê±°ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)', 'ì§ì¥ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)']],
            left_on=['TA_YM', 'LEGAL_DONG'],
            right_on=['TA_YM', 'í–‰ì êµ¬ì—­'],
            how='left'
        )

        print(f"âœ“ í†µí•© ë°ì´í„°: {len(self.merged_data):,}ê±´\n")

    def extract_numeric_value(self, value_str):
        """êµ¬ê°„ ë¬¸ìì—´ì—ì„œ ì¤‘ê°„ê°’ ì¶”ì¶œ"""
        if pd.isna(value_str) or value_str == '':
            return np.nan

        value_str = str(value_str)

        if '90%ì´ˆê³¼' in value_str or 'í•˜ìœ„ 10%' in value_str:
            return 95.0

        if '_' in value_str and '%' in value_str:
            parts = value_str.split('_')
            if len(parts) > 1:
                range_part = parts[1].replace('%', '')
                if '-' in range_part:
                    low, high = map(float, range_part.split('-'))
                    return (low + high) / 2
                elif 'ì´í•˜' in range_part:
                    return float(range_part.replace('ì´í•˜', '')) / 2

        return np.nan

    def create_advanced_features(self):
        """ê³ ê¸‰ ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±"""
        print("ğŸ”§ ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")

        # ì •ë ¬
        self.merged_data = self.merged_data.sort_values(['ENCODED_MCT', 'TA_YM'])

        # ìš´ì˜ ê¸°ê°„
        self.merged_data['ìš´ì˜ê°œì›”ìˆ˜'] = self.merged_data.groupby('ENCODED_MCT').cumcount() + 1

        # ìˆ«ìí˜• ë³€í™˜
        numeric_cols = [
            'MCT_OPE_MS_CN', 'RC_M1_SAA', 'RC_M1_TO_UE_CT', 'RC_M1_UE_CUS_CN', 'RC_M1_AV_NP_AT',
            'M12_SME_RY_SAA_PCE_RT', 'M12_SME_BZN_SAA_PCE_RT'
        ]

        for col in numeric_cols:
            if col in self.merged_data.columns:
                self.merged_data[f'{col}_num'] = self.merged_data[col].apply(self.extract_numeric_value)

        # ê³ ê° íŠ¹ì„± ìˆ«ìí˜•
        customer_cols = [
            'M12_MAL_1020_RAT', 'M12_MAL_30_RAT', 'M12_MAL_40_RAT', 'M12_MAL_50_RAT', 'M12_MAL_60_RAT',
            'M12_FME_1020_RAT', 'M12_FME_30_RAT', 'M12_FME_40_RAT', 'M12_FME_50_RAT', 'M12_FME_60_RAT',
            'MCT_UE_CLN_REU_RAT', 'MCT_UE_CLN_NEW_RAT'
        ]

        for col in customer_cols:
            if col in self.merged_data.columns:
                self.merged_data[col] = pd.to_numeric(self.merged_data[col], errors='coerce')

        # === ì‹œê³„ì—´ íŠ¹ì„± ===

        # 1. ë³€í™”ìœ¨ (1ê°œì›”, 3ê°œì›”, 6ê°œì›”)
        key_metrics = ['RC_M1_SAA_num', 'RC_M1_TO_UE_CT_num', 'RC_M1_UE_CUS_CN_num']

        for col in key_metrics:
            if col in self.merged_data.columns:
                # 1ê°œì›” ë³€í™”ìœ¨
                self.merged_data[f'{col}_ë³€í™”ìœ¨_1M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].pct_change(1) * 100

                # 3ê°œì›” ë³€í™”ìœ¨
                self.merged_data[f'{col}_ë³€í™”ìœ¨_3M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].pct_change(3) * 100

                # 6ê°œì›” ë³€í™”ìœ¨
                self.merged_data[f'{col}_ë³€í™”ìœ¨_6M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].pct_change(6) * 100

        # 2. ì´ë™í‰ê·  (3ê°œì›”, 6ê°œì›”)
        for col in key_metrics:
            if col in self.merged_data.columns:
                self.merged_data[f'{col}_MA3'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].transform(
                        lambda x: x.rolling(window=3, min_periods=1).mean()
                    )

                self.merged_data[f'{col}_MA6'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].transform(
                        lambda x: x.rolling(window=6, min_periods=1).mean()
                    )

        # 3. ì¶”ì„¸ (3ê°œì›”, 6ê°œì›” í‰ê·  ë³€í™”ìœ¨)
        for col in key_metrics:
            col_change = f'{col}_ë³€í™”ìœ¨_1M'
            if col_change in self.merged_data.columns:
                self.merged_data[f'{col}_ì¶”ì„¸3M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col_change].transform(
                        lambda x: x.rolling(window=3, min_periods=1).mean()
                    )

                self.merged_data[f'{col}_ì¶”ì„¸6M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col_change].transform(
                        lambda x: x.rolling(window=6, min_periods=1).mean()
                    )

        # 4. ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
        for col in key_metrics:
            if col in self.merged_data.columns:
                self.merged_data[f'{col}_STD3M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].transform(
                        lambda x: x.rolling(window=3, min_periods=1).std()
                    )

        # 5. ìµœëŒ€/ìµœì†Œ ëŒ€ë¹„ ë¹„ìœ¨
        for col in key_metrics:
            if col in self.merged_data.columns:
                self.merged_data[f'{col}_MAX6M'] = \
                    self.merged_data.groupby('ENCODED_MCT')[col].transform(
                        lambda x: x.rolling(window=6, min_periods=1).max()
                    )
                self.merged_data[f'{col}_vs_MAX'] = \
                    (self.merged_data[col] / self.merged_data[f'{col}_MAX6M'] * 100)

        # 6. ê³„ì ˆì„± (ì›”ë³„ ë”ë¯¸)
        self.merged_data['ì›”'] = self.merged_data['TA_YM'].dt.month
        self.merged_data['ë¶„ê¸°'] = self.merged_data['TA_YM'].dt.quarter

        # 7. ì—°ì† í•˜ë½ ê°œì›” ìˆ˜
        for col in key_metrics:
            col_change = f'{col}_ë³€í™”ìœ¨_1M'
            if col_change in self.merged_data.columns:
                # í•˜ë½ ì—¬ë¶€
                self.merged_data[f'{col}_í•˜ë½ì—¬ë¶€'] = (self.merged_data[col_change] < 0).astype(int)

                # ì—°ì† í•˜ë½ ê°œì›”
                def count_consecutive_decline(group):
                    result = []
                    count = 0
                    for val in group:
                        if val == 1:
                            count += 1
                        else:
                            count = 0
                        result.append(count)
                    return pd.Series(result, index=group.index)

                self.merged_data[f'{col}_ì—°ì†í•˜ë½'] = \
                    self.merged_data.groupby('ENCODED_MCT')[f'{col}_í•˜ë½ì—¬ë¶€'].apply(count_consecutive_decline).values

        # 8. ì„ëŒ€ë£Œ ëŒ€ë¹„ ë§¤ì¶œ íš¨ìœ¨
        if 'ì „ì²´(ë‹¨ìœ„:ì›/í‰)' in self.merged_data.columns and 'RC_M1_SAA_num' in self.merged_data.columns:
            self.merged_data['ì„ëŒ€ë£ŒëŒ€ë¹„ë§¤ì¶œíš¨ìœ¨'] = \
                self.merged_data['RC_M1_SAA_num'] / (self.merged_data['ì „ì²´(ë‹¨ìœ„:ì›/í‰)'] / 1000 + 1)

        # 9. ìœ ë™ì¸êµ¬ ëŒ€ë¹„ ë§¤ì¶œ íš¨ìœ¨
        if 'ìœ ë™ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)' in self.merged_data.columns and 'RC_M1_SAA_num' in self.merged_data.columns:
            self.merged_data['ìœ ë™ì¸êµ¬ëŒ€ë¹„ë§¤ì¶œ'] = \
                self.merged_data['RC_M1_SAA_num'] / (self.merged_data['ìœ ë™ì¸êµ¬(ë‹¨ìœ„:ëª…/1ha)'] / 1000 + 1)

        # 10. ê³ ê° ë‹¤ì–‘ì„± ì§€ìˆ˜ (ì„±ë³„/ì—°ë ¹ë³„ ë¶„í¬ì˜ ì—”íŠ¸ë¡œí”¼)
        gender_age_cols = [col for col in customer_cols if 'MAL' in col or 'FME' in col]
        if gender_age_cols:
            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
            gender_age_data = self.merged_data[gender_age_cols].fillna(0)

            def calculate_entropy(row):
                probs = row / (row.sum() + 1e-10)
                probs = probs[probs > 0]
                return -np.sum(probs * np.log2(probs + 1e-10))

            self.merged_data['ê³ ê°ë‹¤ì–‘ì„±ì§€ìˆ˜'] = gender_age_data.apply(calculate_entropy, axis=1)

        print(f"âœ“ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(self.merged_data.columns)}ê°œ ì»¬ëŸ¼\n")

    def create_target_labels(self):
        """íƒ€ê²Ÿ ë ˆì´ë¸” ìƒì„± (ë£° ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµìš© ë ˆì´ë¸” ìƒì„±)"""
        print("ğŸ¯ íƒ€ê²Ÿ ë ˆì´ë¸” ìƒì„± ì¤‘...")

        # ìœ„í—˜ì ìˆ˜ ê³„ì‚° (ë£° ê¸°ë°˜)
        self.merged_data['ìœ„í—˜ì ìˆ˜_rule'] = 0

        # 1. ë§¤ì¶œ í•˜ë½
        sales_trend = self.merged_data['RC_M1_SAA_num_ì¶”ì„¸3M'].fillna(0)
        self.merged_data.loc[sales_trend < -30, 'ìœ„í—˜ì ìˆ˜_rule'] += 40
        self.merged_data.loc[(sales_trend >= -30) & (sales_trend < -15), 'ìœ„í—˜ì ìˆ˜_rule'] += 30
        self.merged_data.loc[(sales_trend >= -15) & (sales_trend < -5), 'ìœ„í—˜ì ìˆ˜_rule'] += 15

        # 2. ì´ìš©ê±´ìˆ˜ ê°ì†Œ
        usage_trend = self.merged_data['RC_M1_TO_UE_CT_num_ì¶”ì„¸3M'].fillna(0)
        self.merged_data.loc[usage_trend < -30, 'ìœ„í—˜ì ìˆ˜_rule'] += 30
        self.merged_data.loc[(usage_trend >= -30) & (usage_trend < -15), 'ìœ„í—˜ì ìˆ˜_rule'] += 20
        self.merged_data.loc[(usage_trend >= -15) & (usage_trend < -5), 'ìœ„í—˜ì ìˆ˜_rule'] += 10

        # 3. ê³ ê° ìˆ˜ ê°ì†Œ
        customer_trend = self.merged_data['RC_M1_UE_CUS_CN_num_ì¶”ì„¸3M'].fillna(0)
        self.merged_data.loc[customer_trend < -30, 'ìœ„í—˜ì ìˆ˜_rule'] += 20
        self.merged_data.loc[(customer_trend >= -30) & (customer_trend < -15), 'ìœ„í—˜ì ìˆ˜_rule'] += 13
        self.merged_data.loc[(customer_trend >= -15) & (customer_trend < -5), 'ìœ„í—˜ì ìˆ˜_rule'] += 7

        # 4. ì ˆëŒ€ ë§¤ì¶œ ìˆ˜ì¤€
        sales_level = self.merged_data['RC_M1_SAA_num'].fillna(50)
        self.merged_data.loc[sales_level > 90, 'ìœ„í—˜ì ìˆ˜_rule'] += 10
        self.merged_data.loc[(sales_level > 75) & (sales_level <= 90), 'ìœ„í—˜ì ìˆ˜_rule'] += 7

        # 5. ì—°ì† í•˜ë½
        if 'RC_M1_SAA_num_ì—°ì†í•˜ë½' in self.merged_data.columns:
            self.merged_data.loc[self.merged_data['RC_M1_SAA_num_ì—°ì†í•˜ë½'] >= 3, 'ìœ„í—˜ì ìˆ˜_rule'] += 10

        # 6. ì¬êµ¬ë§¤ìœ¨
        if 'MCT_UE_CLN_REU_RAT' in self.merged_data.columns:
            reuse = self.merged_data['MCT_UE_CLN_REU_RAT'].fillna(50)
            self.merged_data.loc[reuse < 10, 'ìœ„í—˜ì ìˆ˜_rule'] += 5

        # ê²½ë³´ ë ˆë²¨ (0-3)
        conditions = [
            self.merged_data['ìœ„í—˜ì ìˆ˜_rule'] < 25,
            (self.merged_data['ìœ„í—˜ì ìˆ˜_rule'] >= 25) & (self.merged_data['ìœ„í—˜ì ìˆ˜_rule'] < 50),
            (self.merged_data['ìœ„í—˜ì ìˆ˜_rule'] >= 50) & (self.merged_data['ìœ„í—˜ì ìˆ˜_rule'] < 75),
            self.merged_data['ìœ„í—˜ì ìˆ˜_rule'] >= 75
        ]
        self.merged_data['ê²½ë³´ë ˆë²¨'] = np.select(conditions, [0, 1, 2, 3], default=0)

        print(f"âœ“ ë ˆì´ë¸” ë¶„í¬:")
        for level in range(4):
            count = (self.merged_data['ê²½ë³´ë ˆë²¨'] == level).sum()
            pct = count / len(self.merged_data) * 100
            print(f"  {self.WARNING_LEVELS[level]['emoji']} {self.WARNING_LEVELS[level]['name']}: {count:,}ê±´ ({pct:.1f}%)")
        print()

    def prepare_features(self):
        """LightGBM í•™ìŠµìš© íŠ¹ì„± ì¤€ë¹„"""
        print("ğŸ”¨ í•™ìŠµìš© íŠ¹ì„± ì¤€ë¹„ ì¤‘...")

        # ê²°ì¸¡ì¹˜ê°€ ë„ˆë¬´ ë§ê±°ë‚˜ ì‚¬ìš©í•˜ì§€ ì•Šì„ ì»¬ëŸ¼ ì œì™¸
        exclude_cols = [
            'ENCODED_MCT', 'TA_YM', 'MCT_BSE_AR', 'MCT_NM', 'MCT_BRD_NUM', 'ARE_D', 'MCT_ME_D',
            '__filled_flag__', '__fill_method__', '__impute_source__',
            'ê²½ë³´ë ˆë²¨', 'ìœ„í—˜ì ìˆ˜_rule', 'LEGAL_DONG', 'í–‰ì •êµ¬ì—­', 'í–‰ì êµ¬ì—­',
            'MCT_SIGUNGU_NM', 'ê¸°ê°„'
        ]

        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_cols = ['HPSN_MCT_ZCD_NM', 'HPSN_MCT_BZN_CD_NM', 'ì›”', 'ë¶„ê¸°']

        for col in categorical_cols:
            if col in self.merged_data.columns:
                le = LabelEncoder()
                self.merged_data[f'{col}_encoded'] = le.fit_transform(
                    self.merged_data[col].fillna('Unknown').astype(str)
                )
                self.label_encoders[col] = le

        # íŠ¹ì„± ì»¬ëŸ¼ ì„ íƒ
        all_cols = set(self.merged_data.columns)
        exclude_set = set(exclude_cols)

        # ìˆ«ìí˜• + ì¸ì½”ë”©ëœ ë²”ì£¼í˜•ë§Œ
        potential_features = all_cols - exclude_set

        self.feature_cols = []
        for col in potential_features:
            if self.merged_data[col].dtype in ['int64', 'float64', 'int32', 'float32']:
                # ê²°ì¸¡ì¹˜ê°€ 80% ì´ìƒì¸ ì»¬ëŸ¼ ì œì™¸
                missing_rate = self.merged_data[col].isna().sum() / len(self.merged_data)
                if missing_rate < 0.8:
                    self.feature_cols.append(col)

        print(f"âœ“ ì„ íƒëœ íŠ¹ì„±: {len(self.feature_cols)}ê°œ")
        print(f"  ì£¼ìš” íŠ¹ì„±: {self.feature_cols[:10]}")
        print()

    def train_lgbm_model(self):
        """LightGBM ëª¨ë¸ í•™ìŠµ"""
        print("=" * 80)
        print("ğŸš€ LightGBM ëª¨ë¸ í•™ìŠµ ì¤‘...")
        print("=" * 80)

        # í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ìš´ì˜ê°œì›”ìˆ˜ 3ê°œì›” ì´ìƒë§Œ ì‚¬ìš©)
        train_data = self.merged_data[self.merged_data['ìš´ì˜ê°œì›”ìˆ˜'] >= 3].copy()

        X = train_data[self.feature_cols].fillna(0)
        y = train_data['ê²½ë³´ë ˆë²¨']

        # Train/Test ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        print(f"âœ“ í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê±´")
        print(f"âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê±´\n")

        # LightGBM ë°ì´í„°ì…‹
        lgb_train = lgb.Dataset(X_train, y_train)
        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)

        # íŒŒë¼ë¯¸í„°
        params = {
            'objective': 'multiclass',
            'num_class': 4,
            'metric': 'multi_logloss',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1,
            'max_depth': 7,
            'min_child_samples': 20
        }

        # í•™ìŠµ
        print("ğŸ”„ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        self.model = lgb.train(
            params,
            lgb_train,
            num_boost_round=500,
            valid_sets=[lgb_train, lgb_eval],
            valid_names=['train', 'valid'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=50),
                lgb.log_evaluation(period=50)
            ]
        )

        print("\nâœ“ í•™ìŠµ ì™„ë£Œ!\n")

        # ì˜ˆì¸¡ ë° í‰ê°€
        y_pred = self.model.predict(X_test, num_iteration=self.model.best_iteration)
        y_pred_class = np.argmax(y_pred, axis=1)

        print("=" * 80)
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
        print("=" * 80)
        print("\n[ë¶„ë¥˜ ë¦¬í¬íŠ¸]")
        print(classification_report(
            y_test, y_pred_class,
            target_names=[f"{self.WARNING_LEVELS[i]['emoji']} {self.WARNING_LEVELS[i]['name']}"
                          for i in range(4)]
        ))

        # ì „ì²´ ë°ì´í„°ì— ì˜ˆì¸¡ ìˆ˜í–‰
        print("ğŸ”® ì „ì²´ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...")
        X_all = self.merged_data[self.feature_cols].fillna(0)
        y_pred_all = self.model.predict(X_all, num_iteration=self.model.best_iteration)

        self.merged_data['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'] = np.argmax(y_pred_all, axis=1)
        self.merged_data['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _0'] = y_pred_all[:, 0]
        self.merged_data['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _1'] = y_pred_all[:, 1]
        self.merged_data['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _2'] = y_pred_all[:, 2]
        self.merged_data['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _3'] = y_pred_all[:, 3]

        # ìœ„í—˜ì ìˆ˜ (0-100)
        self.merged_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'] = (
            self.merged_data['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _1'] * 25 +
            self.merged_data['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _2'] * 50 +
            self.merged_data['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _3'] * 75
        )

        print("âœ“ ì˜ˆì¸¡ ì™„ë£Œ!\n")

        return X_test, y_test, y_pred

    def visualize_feature_importance(self, save_path='feature_importance.png'):
        """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
        print("ğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” ì¤‘...")

        fig, axes = plt.subplots(1, 2, figsize=(18, 8))
        fig.suptitle('LightGBM íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„', fontsize=18, fontweight='bold')

        # 1. Gain ê¸°ì¤€
        importance_gain = self.model.feature_importance(importance_type='gain')
        indices = np.argsort(importance_gain)[::-1][:30]

        ax1 = axes[0]
        ax1.barh(range(30), importance_gain[indices], color='skyblue', edgecolor='black')
        ax1.set_yticks(range(30))
        ax1.set_yticklabels([self.feature_cols[i] for i in indices], fontsize=9)
        ax1.invert_yaxis()
        ax1.set_xlabel('ì¤‘ìš”ë„ (Gain)', fontsize=12, fontweight='bold')
        ax1.set_title('íŠ¹ì„± ì¤‘ìš”ë„ - Gain ê¸°ì¤€ (Top 30)', fontsize=14, fontweight='bold', pad=10)
        ax1.grid(axis='x', alpha=0.3, linestyle='--')

        # 2. Split ê¸°ì¤€
        importance_split = self.model.feature_importance(importance_type='split')
        indices_split = np.argsort(importance_split)[::-1][:30]

        ax2 = axes[1]
        ax2.barh(range(30), importance_split[indices_split], color='lightcoral', edgecolor='black')
        ax2.set_yticks(range(30))
        ax2.set_yticklabels([self.feature_cols[i] for i in indices_split], fontsize=9)
        ax2.invert_yaxis()
        ax2.set_xlabel('ì¤‘ìš”ë„ (Split)', fontsize=12, fontweight='bold')
        ax2.set_title('íŠ¹ì„± ì¤‘ìš”ë„ - Split ê¸°ì¤€ (Top 30)', fontsize=14, fontweight='bold', pad=10)
        ax2.grid(axis='x', alpha=0.3, linestyle='--')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def visualize_confusion_matrix(self, y_test, y_pred, save_path='confusion_matrix.png'):
        """í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"""
        print("ğŸ“Š í˜¼ë™ í–‰ë ¬ ì‹œê°í™” ì¤‘...")

        y_pred_class = np.argmax(y_pred, axis=1)
        cm = confusion_matrix(y_test, y_pred_class)

        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                    xticklabels=[f"{self.WARNING_LEVELS[i]['emoji']} {self.WARNING_LEVELS[i]['name']}"
                                for i in range(4)],
                    yticklabels=[f"{self.WARNING_LEVELS[i]['emoji']} {self.WARNING_LEVELS[i]['name']}"
                                for i in range(4)],
                    cbar_kws={'label': 'ê±´ìˆ˜'})

        ax.set_xlabel('ì˜ˆì¸¡ ê²½ë³´ ë ˆë²¨', fontsize=13, fontweight='bold')
        ax.set_ylabel('ì‹¤ì œ ê²½ë³´ ë ˆë²¨', fontsize=13, fontweight='bold')
        ax.set_title('í˜¼ë™ í–‰ë ¬ (Confusion Matrix)', fontsize=16, fontweight='bold', pad=15)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def visualize_predictions(self, save_path='prediction_analysis.png'):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        print("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì¤‘...")

        latest_month = self.merged_data['TA_YM'].max()
        latest_data = self.merged_data[self.merged_data['TA_YM'] == latest_month]

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'LightGBM ê¸°ë°˜ ê²½ì˜ ìœ„ê¸° ì˜ˆì¸¡ ë¶„ì„ ({latest_month.strftime("%Yë…„ %mì›”")})',
                     fontsize=18, fontweight='bold', y=0.995)

        # 1. ì˜ˆì¸¡ ê²½ë³´ ë ˆë²¨ ë¶„í¬
        ax1 = axes[0, 0]
        pred_counts = latest_data['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'].value_counts().sort_index()
        colors = [self.WARNING_LEVELS[i]['color'] for i in range(4)]

        bars = ax1.bar(range(len(pred_counts)), pred_counts.values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
        ax1.set_xticks(range(4))
        ax1.set_xticklabels([f"{self.WARNING_LEVELS[i]['emoji']} {self.WARNING_LEVELS[i]['name']}"
                              for i in range(4)], fontsize=11)
        ax1.set_ylabel('ê°€ë§¹ì  ìˆ˜', fontsize=12, fontweight='bold')
        ax1.set_title('ì˜ˆì¸¡ ê²½ë³´ ë ˆë²¨ë³„ ë¶„í¬', fontsize=14, fontweight='bold', pad=10)
        ax1.grid(axis='y', alpha=0.3, linestyle='--')

        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height):,}ê°œ\n({height/len(latest_data)*100:.1f}%)',
                    ha='center', va='bottom', fontsize=10, fontweight='bold')

        # 2. ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜ ë¶„í¬
        ax2 = axes[0, 1]
        ax2.hist(latest_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'], bins=40, color='steelblue', alpha=0.7, edgecolor='black')
        ax2.axvline(x=25, color='yellow', linestyle='--', linewidth=2, label='ì£¼ì˜')
        ax2.axvline(x=50, color='orange', linestyle='--', linewidth=2, label='ê²½ê³ ')
        ax2.axvline(x=75, color='red', linestyle='--', linewidth=2, label='ìœ„í—˜')
        ax2.set_xlabel('ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜', fontsize=12, fontweight='bold')
        ax2.set_ylabel('ê°€ë§¹ì  ìˆ˜', fontsize=12, fontweight='bold')
        ax2.set_title('ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜ ë¶„í¬', fontsize=14, fontweight='bold', pad=10)
        ax2.legend(fontsize=10)
        ax2.grid(axis='y', alpha=0.3, linestyle='--')

        # 3. ë£° ê¸°ë°˜ vs ML ì˜ˆì¸¡ ë¹„êµ
        ax3 = axes[1, 0]
        comparison = pd.crosstab(latest_data['ê²½ë³´ë ˆë²¨'], latest_data['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'])
        sns.heatmap(comparison, annot=True, fmt='d', cmap='YlOrRd', ax=ax3, cbar_kws={'label': 'ê±´ìˆ˜'})
        ax3.set_xlabel('ML ì˜ˆì¸¡ ë ˆë²¨', fontsize=12, fontweight='bold')
        ax3.set_ylabel('ë£° ê¸°ë°˜ ë ˆë²¨', fontsize=12, fontweight='bold')
        ax3.set_title('ë£° ê¸°ë°˜ vs ML ì˜ˆì¸¡ ë¹„êµ', fontsize=14, fontweight='bold', pad=10)
        ax3.set_xticklabels([self.WARNING_LEVELS[i]['name'] for i in range(4)], rotation=0)
        ax3.set_yticklabels([self.WARNING_LEVELS[i]['name'] for i in range(4)], rotation=0)

        # 4. ì—…ì¢…ë³„ í‰ê·  ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜
        ax4 = axes[1, 1]
        if 'HPSN_MCT_ZCD_NM' in latest_data.columns:
            industry_risk = latest_data.groupby('HPSN_MCT_ZCD_NM')['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].mean().sort_values(ascending=False).head(15)

            bars = ax4.barh(range(len(industry_risk)), industry_risk.values, color='coral', alpha=0.7, edgecolor='black')
            ax4.set_yticks(range(len(industry_risk)))
            ax4.set_yticklabels(industry_risk.index, fontsize=9)
            ax4.set_xlabel('í‰ê·  ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜', fontsize=12, fontweight='bold')
            ax4.set_title('ì—…ì¢…ë³„ í‰ê·  ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜ (Top 15)', fontsize=14, fontweight='bold', pad=10)
            ax4.grid(axis='x', alpha=0.3, linestyle='--')

            for i, bar in enumerate(bars):
                width = bar.get_width()
                if width >= 75:
                    bar.set_color('red')
                elif width >= 50:
                    bar.set_color('orange')
                elif width >= 25:
                    bar.set_color('yellow')
                else:
                    bar.set_color('green')
                bar.set_alpha(0.7)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def visualize_merchant_lgbm(self, encoded_mct, save_path='merchant_lgbm_detail.png'):
        """LightGBM ì˜ˆì¸¡ ê¸°ë°˜ ê°€ë§¹ì  ìƒì„¸ ë¶„ì„"""
        print(f"ğŸ” ê°€ë§¹ì  ìƒì„¸ ë¶„ì„ (LightGBM): {encoded_mct}")

        merchant_ts = self.merged_data[self.merged_data['ENCODED_MCT'] == encoded_mct].copy()
        merchant_ts = merchant_ts.sort_values('TA_YM')

        if len(merchant_ts) == 0:
            print(f"âŒ í•´ë‹¹ ê°€ë§¹ì  ë°ì´í„° ì—†ìŒ")
            return

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        mct_info = merchant_ts.iloc[-1]
        fig.suptitle(f'ê°€ë§¹ì  ìƒì„¸ ë¶„ì„ (LightGBM ì˜ˆì¸¡)\n{mct_info.get("MCT_NM", "N/A")} ({mct_info.get("HPSN_MCT_BZN_CD_NM", "N/A")})',
                     fontsize=18, fontweight='bold', y=0.98)

        # 1. ê²½ë³´ ë ˆë²¨ ë¹„êµ (ë£° vs ML)
        ax1 = axes[0, 0]
        x = range(len(merchant_ts))
        ax1.plot(merchant_ts['TA_YM'], merchant_ts['ê²½ë³´ë ˆë²¨'],
                marker='o', linewidth=2.5, label='ë£° ê¸°ë°˜', color='#2E86AB')
        ax1.plot(merchant_ts['TA_YM'], merchant_ts['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'],
                marker='s', linewidth=2.5, label='ML ì˜ˆì¸¡', color='#F18F01')
        ax1.fill_between(merchant_ts['TA_YM'], merchant_ts['ê²½ë³´ë ˆë²¨'], alpha=0.2, color='#2E86AB')
        ax1.fill_between(merchant_ts['TA_YM'], merchant_ts['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'], alpha=0.2, color='#F18F01')

        ax1.set_ylabel('ê²½ë³´ ë ˆë²¨', fontsize=11, fontweight='bold')
        ax1.set_yticks([0, 1, 2, 3])
        ax1.set_yticklabels([self.WARNING_LEVELS[i]['name'] for i in range(4)])
        ax1.set_title('ê²½ë³´ ë ˆë²¨ ì¶”ì´ (ë£° ê¸°ë°˜ vs ML ì˜ˆì¸¡)', fontsize=13, fontweight='bold', pad=10)
        ax1.legend(fontsize=10, loc='best')
        ax1.grid(True, alpha=0.3, linestyle='--')
        ax1.tick_params(axis='x', rotation=45)

        # 2. ìœ„í—˜ í™•ë¥  ë¶„í¬
        ax2 = axes[0, 1]
        ax2.stackplot(merchant_ts['TA_YM'],
                     merchant_ts['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _0'] * 100,
                     merchant_ts['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _1'] * 100,
                     merchant_ts['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _2'] * 100,
                     merchant_ts['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _3'] * 100,
                     labels=['ì•ˆì „', 'ì£¼ì˜', 'ê²½ê³ ', 'ìœ„í—˜'],
                     colors=['green', 'yellow', 'orange', 'red'],
                     alpha=0.7)
        ax2.set_ylabel('ìœ„í—˜ í™•ë¥  (%)', fontsize=11, fontweight='bold')
        ax2.set_title('ë ˆë²¨ë³„ ìœ„í—˜ í™•ë¥  ì¶”ì´', fontsize=13, fontweight='bold', pad=10)
        ax2.legend(loc='upper left', fontsize=9)
        ax2.grid(True, alpha=0.3, linestyle='--')
        ax2.tick_params(axis='x', rotation=45)

        # 3. ìœ„í—˜ì ìˆ˜ ë¹„êµ
        ax3 = axes[1, 0]
        ax3.plot(merchant_ts['TA_YM'], merchant_ts['ìœ„í—˜ì ìˆ˜_rule'],
                marker='o', linewidth=2, label='ë£° ê¸°ë°˜ ì ìˆ˜', color='#2E86AB')
        ax3.plot(merchant_ts['TA_YM'], merchant_ts['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'],
                marker='s', linewidth=2, label='ML ì˜ˆì¸¡ ì ìˆ˜', color='#F18F01')

        ax3.axhline(y=25, color='yellow', linestyle='--', linewidth=1.5, alpha=0.5)
        ax3.axhline(y=50, color='orange', linestyle='--', linewidth=1.5, alpha=0.5)
        ax3.axhline(y=75, color='red', linestyle='--', linewidth=1.5, alpha=0.5)

        ax3.set_ylabel('ìœ„í—˜ì ìˆ˜', fontsize=11, fontweight='bold')
        ax3.set_title('ìœ„í—˜ì ìˆ˜ ë¹„êµ', fontsize=13, fontweight='bold', pad=10)
        ax3.legend(fontsize=10, loc='best')
        ax3.grid(True, alpha=0.3, linestyle='--')
        ax3.tick_params(axis='x', rotation=45)

        # 4. í˜„ì¬ ìƒíƒœ ìš”ì•½
        ax4 = axes[1, 1]
        ax4.axis('off')

        latest = merchant_ts.iloc[-1]
        pred_level = int(latest['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'])
        pred_info = self.WARNING_LEVELS[pred_level]

        summary = f"""
        ã€ ML ì˜ˆì¸¡ ê²½ë³´ ìƒíƒœ ã€‘

        {pred_info['emoji']} ì˜ˆì¸¡ ë ˆë²¨: {pred_info['name']}
        ğŸ“Š ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜: {latest['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜']:.1f}ì 

        ã€ ë ˆë²¨ë³„ í™•ë¥  ã€‘

        ğŸŸ¢ ì•ˆì „: {latest['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _0']*100:.1f}%
        ğŸŸ¡ ì£¼ì˜: {latest['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _1']*100:.1f}%
        ğŸŸ  ê²½ê³ : {latest['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _2']*100:.1f}%
        ğŸ”´ ìœ„í—˜: {latest['ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _3']*100:.1f}%

        ã€ ìµœê·¼ ì¶”ì„¸ ã€‘

        ğŸ“ˆ ë§¤ì¶œ ë³€í™”: {latest.get('RC_M1_SAA_num_ì¶”ì„¸3M', 0):.1f}%
        ğŸ‘¥ ê³ ê° ë³€í™”: {latest.get('RC_M1_UE_CUS_CN_num_ì¶”ì„¸3M', 0):.1f}%
        ğŸ”„ ì—°ì† í•˜ë½: {latest.get('RC_M1_SAA_num_ì—°ì†í•˜ë½', 0):.0f}ê°œì›”

        ã€ AI ê¶Œì¥ ì¡°ì¹˜ ã€‘
        """

        if pred_level == 3:
            summary += "\nğŸ”´ ì¦‰ê° ëŒ€ì‘ í•„ìš”\n    ML ëª¨ë¸ì´ ë†’ì€ ìœ„í—˜ ê°ì§€\n    ì „ë¬¸ ì»¨ì„¤íŒ… ê¶Œì¥"
        elif pred_level == 2:
            summary += "\nğŸŸ  ë©´ë°€í•œ ëª¨ë‹ˆí„°ë§\n    ê²½ì˜ ê°œì„  ë°©ì•ˆ ìˆ˜ë¦½\n    ì •ê¸° ì ê²€ ê°•í™”"
        elif pred_level == 1:
            summary += "\nğŸŸ¡ ì˜ˆë°©ì  ì¡°ì¹˜\n    ì¶”ì„¸ ê´€ì°° í•„ìš”\n    ê°œì„  ê¸°íšŒ íƒìƒ‰"
        else:
            summary += "\nğŸŸ¢ ì•ˆì •ì  ìš´ì˜\n    í˜„ ì „ëµ ìœ ì§€\n    ì„±ì¥ ê¸°íšŒ ëª¨ìƒ‰"

        ax4.text(0.1, 0.95, summary, transform=ax4.transAxes,
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor=pred_info['color'], alpha=0.2),
                family=['gulim', 'Symbol'])

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}\n")
        plt.show()

    def generate_report(self, output_file='lgbm_warning_report.csv'):
        """ê²½ë³´ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ“ ê²½ë³´ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

        latest_month = self.merged_data['TA_YM'].max()
        latest_data = self.merged_data[self.merged_data['TA_YM'] == latest_month].copy()

        report_cols = [
            'ENCODED_MCT', 'MCT_NM', 'HPSN_MCT_BZN_CD_NM', 'MCT_SIGUNGU_NM',
            'ê²½ë³´ë ˆë²¨', 'ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨', 'ìœ„í—˜ì ìˆ˜_rule', 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜',
            'ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _0', 'ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _1', 'ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _2', 'ì˜ˆì¸¡_ìœ„í—˜í™•ë¥ _3',
            'RC_M1_SAA_num', 'RC_M1_SAA_num_ì¶”ì„¸3M', 'RC_M1_SAA_num_ì—°ì†í•˜ë½',
            'ìš´ì˜ê°œì›”ìˆ˜'
        ]

        report_cols = [col for col in report_cols if col in latest_data.columns]
        report = latest_data[report_cols].copy()
        report = report.sort_values('ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜', ascending=False)

        report.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ“ ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")
        print(f"  ì´ {len(report):,}ê°œ ê°€ë§¹ì \n")

        return report

    def print_summary(self):
        """ìš”ì•½ í†µê³„"""
        print("=" * 80)
        print("ğŸ“Š LightGBM ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ - ìš”ì•½")
        print("=" * 80)

        latest_month = self.merged_data['TA_YM'].max()
        latest_data = self.merged_data[self.merged_data['TA_YM'] == latest_month]

        print(f"\nğŸ“… ë¶„ì„ ê¸°ì¤€: {latest_month.strftime('%Yë…„ %mì›”')}")
        print(f"ğŸ¢ ë¶„ì„ ê°€ë§¹ì  ìˆ˜: {len(latest_data):,}ê°œ\n")

        print("ã€ ML ì˜ˆì¸¡ ê²½ë³´ ë ˆë²¨ë³„ í˜„í™© ã€‘")
        for level in range(4):
            name = self.WARNING_LEVELS[level]['name']
            emoji = self.WARNING_LEVELS[level]['emoji']
            count = (latest_data['ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨'] == level).sum()
            pct = count / len(latest_data) * 100
            print(f"  {emoji} {name:4s}: {count:6,}ê°œ ({pct:5.1f}%)")

        print(f"\nã€ ì˜ˆì¸¡ ìœ„í—˜ì ìˆ˜ í†µê³„ ã€‘")
        print(f"  í‰ê· : {latest_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].mean():.1f}ì ")
        print(f"  ì¤‘ì•™ê°’: {latest_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].median():.1f}ì ")
        print(f"  ìµœëŒ€: {latest_data['ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜'].max():.1f}ì ")

        print("\nã€ ê³ ìœ„í—˜ ê°€ë§¹ì  (Top 10) ã€‘")
        high_risk = latest_data.nlargest(10, 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜')[
            ['MCT_NM', 'HPSN_MCT_BZN_CD_NM', 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜', 'ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨']
        ]
        for idx, row in enumerate(high_risk.itertuples(), 1):
            level_name = self.WARNING_LEVELS[int(row.ì˜ˆì¸¡_ê²½ë³´ë ˆë²¨)]['name']
            print(f"  {idx:2d}. {row.MCT_NM:15s} | {row.HPSN_MCT_BZN_CD_NM:15s} | {row.ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜:5.1f}ì  | {level_name}")

        print("\n" + "=" * 80 + "\n")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("=" * 80)
    print("ğŸš€ LightGBM ê¸°ë°˜ ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ")
    print("=" * 80)
    print()

    ews = LGBMEarlyWarningSystem(data_path='./data/')

    # 1. ë°ì´í„° ë¡œë“œ
    ews.load_data()

    # 2. ë°ì´í„° í†µí•©
    ews.merge_all_data()

    # 3. ê³ ê¸‰ íŠ¹ì„± ìƒì„±
    ews.create_advanced_features()

    # 4. íƒ€ê²Ÿ ë ˆì´ë¸” ìƒì„±
    ews.create_target_labels()

    # 5. íŠ¹ì„± ì¤€ë¹„
    ews.prepare_features()

    # 6. LightGBM ëª¨ë¸ í•™ìŠµ
    X_test, y_test, y_pred = ews.train_lgbm_model()

    # 7. ìš”ì•½ í†µê³„
    ews.print_summary()

    # 8. ì‹œê°í™”
    print("ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...\n")

    ews.visualize_feature_importance('lgbm_feature_importance.png')
    ews.visualize_confusion_matrix(y_test, y_pred, 'lgbm_confusion_matrix.png')
    ews.visualize_predictions('lgbm_prediction_analysis.png')

    # 9. ë¦¬í¬íŠ¸ ìƒì„±
    report = ews.generate_report('lgbm_warning_report.csv')

    # 10. ê³ ìœ„í—˜ ê°€ë§¹ì  ìƒì„¸ ë¶„ì„
    print("ğŸ” ê³ ìœ„í—˜ ê°€ë§¹ì  ìƒì„¸ ë¶„ì„...\n")
    top_risk = report.nlargest(3, 'ì˜ˆì¸¡_ìœ„í—˜ì ìˆ˜')['ENCODED_MCT'].values

    for idx, mct_id in enumerate(top_risk, 1):
        ews.visualize_merchant_lgbm(mct_id, f'lgbm_merchant_top{idx}.png')

    print("=" * 80)
    print("âœ… LightGBM ê²½ì˜ ìœ„ê¸° ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ ì™„ë£Œ!")
    print("=" * 80)
    print("\nìƒì„±ëœ íŒŒì¼:")
    print("  ğŸ“Š lgbm_feature_importance.png - íŠ¹ì„± ì¤‘ìš”ë„")
    print("  ğŸ“Š lgbm_confusion_matrix.png - í˜¼ë™ í–‰ë ¬")
    print("  ğŸ“Š lgbm_prediction_analysis.png - ì˜ˆì¸¡ ë¶„ì„")
    print("  ğŸ” lgbm_merchant_top1~3.png - ê³ ìœ„í—˜ ê°€ë§¹ì  ìƒì„¸")
    print("  ğŸ“ lgbm_warning_report.csv - ì „ì²´ ê²½ë³´ ë¦¬í¬íŠ¸")
    print()


if __name__ == "__main__":
    main()
